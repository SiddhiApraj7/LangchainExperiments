{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(find_dotenv())\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_model = \"gpt-3.5-turbo\"\n",
    "llm = OpenAI(temperature=0.7)\n",
    "chat_model= ChatOpenAI(temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "As an AI, I do not have access to live weather data. However, according to current forecasts, the weather in Mumbai is typically hot and humid with temperatures ranging from 25-35 degrees Celsius (77-95 degrees Fahrenheit). Monsoon season in Mumbai lasts from June to September, with heavy rainfall and occasional thunderstorms.\n"
     ]
    }
   ],
   "source": [
    "print(llm.predict(\"What is the weather in Mumbai?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently, the weather in Mumbai is partly cloudy with a temperature of around 32°C (90°F).\n"
     ]
    }
   ],
   "source": [
    "print(chat_model.predict(\"What is the weather in Mumbai?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='The universe is approximately 13.8 billion years old. This age is based on scientific observations and measurements of the cosmic microwave background radiation, as well as the expansion rate of the universe.' response_metadata={'token_usage': {'completion_tokens': 38, 'prompt_tokens': 13, 'total_tokens': 51}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-d5af00f6-a0c2-4904-b35d-a71d76cea129-0'\n"
     ]
    }
   ],
   "source": [
    "prompt = \"How old is the universe?\"\n",
    "messages = [HumanMessage(content=prompt)]\n",
    "print(chat_model.predict_messages(messages).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_model= ChatOpenAI(temperature=0.7, model=llm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=llm_model):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_review = \"\"\"Your product is terrible! I don't know how you were able to get this to the market. I don't want this! Actually no one would want this. Seriously, Give me my money now!\"\"\"\n",
    "tone = \"\"\"Proper English in a nice, warm and respectful tone\"\"\"\n",
    "language = \"\"\"Korean\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "promp = f\"\"\" Rewrite the following {customer_review} in {tone} and then please translate the new review message into {language}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am disappointed with your product. I am unsure how it was approved for the market. Unfortunately, it does not meet my needs and I believe it would not appeal to others as well. I kindly request a refund. Thank you.\n",
      "\n",
      "Korean translation:\n",
      "당신의 제품에 실망했습니다. 시장에 출시되었다는 것에 의문을 가지고 있습니다. 안타깝게도 제 요구를 충족시키지 못하며 다른 사람들에게도 매력적이지 않을 것으로 생각됩니다. 환불을 요청합니다. 감사합니다.\n"
     ]
    }
   ],
   "source": [
    "rewrite = get_completion(prompt = promp)\n",
    "print(rewrite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Built-in Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_string = \"\"\"Translate the following text {customer_review} into Italian in a polite tone. Also, give it a {field}\"\"\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(template_string)\n",
    "\n",
    "translation_message = prompt_template.format_messages(\n",
    "    customer_review = customer_review,\n",
    "    field = \"thumbs down\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il tuo prodotto è terribile! Non so come sei riuscito a farlo arrivare sul mercato. Non lo voglio! In realtà, nessuno lo vorrebbe. Sul serio, restituiscimi i soldi adesso! 👎\n"
     ]
    }
   ],
   "source": [
    "response = chat_model(translation_message)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Langchain Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(temperature=0.0, model=llm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_response = \"\"\"\n",
    "Here's our itinerary for our upcoming trip to Europe.\n",
    "We leave from Denver, Colorado airport at 8:45 pm, and arrive in Amsterdam 10 hours later\n",
    "at Schipol Airport.\n",
    "We'll grab a ride to our airbnb and maybe stop somewhere for breakfast before \n",
    "taking a nap.\n",
    "\n",
    "Some sightseeing will follow for a couple of hours. \n",
    "We will then go shop for gifts \n",
    "to bring back to our children and friends.  \n",
    "\n",
    "The next morning, at 7:45am we'll drive to to Belgium, Brussels - it should only take aroud 3 hours.\n",
    "While in Brussels we want to explore the city to its fullest - no rock left unturned!\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_template = \"\"\"\n",
    "From the following email, extract the following information:\n",
    "\n",
    "leave_time: when are they leaving for vacation to Europe. If there's an actual\n",
    "time written, use it, if not write unknown.\n",
    "\n",
    "leave_from: where are they leaving from, the airport or city name and state if\n",
    "available.\n",
    "\n",
    "cities_to_visit: extract the cities they are going to visit. \n",
    "If there are more than one, put them in square brackets like '[\"cityone\", \"citytwo\"].\n",
    "\n",
    "Format the output as JSON with the following keys:\n",
    "leave_time\n",
    "leave_from\n",
    "cities_to_visit\n",
    "\n",
    "email: {email}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = ChatPromptTemplate.from_template(email_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = prompt_template.format_messages(email=email_response)\n",
    "response = chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"leave_time\": \"8:45 pm\",\n",
      "  \"leave_from\": \"Denver, Colorado\",\n",
      "  \"cities_to_visit\": [\"Amsterdam\", \"Brussels\"]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Langchain Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(response.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import ResponseSchema\n",
    "from langchain.output_parsers import StructuredOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "leave_time_schema = ResponseSchema(name=\"leave_time\", description=\"When they are leaving. \\\n",
    "    It's usually a numerical time of the day. \\\n",
    "        If not available, write n/a.\")\n",
    "\n",
    "leave_from_schema = ResponseSchema(name=\"leave_from\", description=\"Where they are leaving from. \\\n",
    "    It's a city, airport, state or province. \\\n",
    "        If not available, write n/a.\")\n",
    "\n",
    "cities_to_visit_schema = ResponseSchema(name=\"cities_to_visit\", description=\"The cities or towns to be visited on the trip. \\\n",
    "    This needs to be a list. \\\n",
    "        If not available, write n/a.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_schema = [\n",
    "    leave_time_schema,\n",
    "    leave_from_schema,\n",
    "    cities_to_visit_schema\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = StructuredOutputParser.from_response_schemas(response_schema)\n",
    "\n",
    "format_instructions = output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_template_revised = \"\"\"\n",
    "From the following email, extract the following information:\n",
    "\n",
    "leave_time: when are they leaving for vacation to Europe. If there's an actual\n",
    "time written, use it, if not write unknown.\n",
    "\n",
    "leave_from: where are they leaving from, the airport or city name and state if\n",
    "available.\n",
    "\n",
    "cities_to_visit: extract the cities they are going to visit. If there are more than \n",
    "one, put them in square brackets like '[\"cityone\", \"citytwo\"].\n",
    "\n",
    "Format the output as JSON with the following keys:\n",
    "leave_time\n",
    "leave_from\n",
    "cities_to_visit\n",
    "\n",
    "email: {email}\n",
    "{format_instructions}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_prompt = ChatPromptTemplate.from_template(template=email_template_revised)\n",
    "messages = prompt_template.format_messages(email = email_response, format_instructions=format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(response.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "Cities:::: Amsterdam\n"
     ]
    }
   ],
   "source": [
    "output_dict = output_parser.parse(response.content)\n",
    "print(type(output_dict))\n",
    "print(f\"Cities:::: {output_dict['cities_to_visit'][0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pydantic Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.pydantic_v1 import BaseModel, Field, validator\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VacationInfo(BaseModel):\n",
    "    leave_time: str = Field(description=\"When they are leaving.\")\n",
    "    leave_from: str = Field(description=\"Where they are leaving from. It's a city, airport, state or province.\")\n",
    "    cities_to_visit: List = Field(description=\"The cities, towns they will be visiting on their trip. This needs to be in a list\")\n",
    "    num_people: int = Field(description=\"this is an integer for a number of people on this trip\")\n",
    "    \n",
    "    @validator('num_people')\n",
    "    def check_num_people(cls, field):\n",
    "        if field <=0:\n",
    "            raise ValueError(\"Badly formatted number\")\n",
    "        return field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "pydantic_parser = PydanticOutputParser(pydantic_object=VacationInfo)\n",
    "format_instructions = pydantic_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_response = \"\"\"\n",
    "Here's our itinerary for our upcoming trip to Europe.\n",
    "There will be 5 of us on this vacation trip.\n",
    "We leave from Denver, Colorado airport at 8:45 pm, and arrive in Amsterdam 10 hours later\n",
    "at Schipol Airport.\n",
    "We'll grab a ride to our airbnb and maybe stop somewhere for breakfast before \n",
    "taking a nap.\n",
    "\n",
    "Some sightseeing will follow for a couple of hours. \n",
    "We will then go shop for gifts \n",
    "to bring back to our children and friends.  \n",
    "\n",
    "The next morning, at 7:45am we'll drive to to Belgium, Brussels - it should only take aroud 3 hours.\n",
    "While in Brussels we want to explore the city to its fullest - no rock left unturned!\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_template_revised = \"\"\"\n",
    "From the following email, extract the following information regarding \n",
    "this trip.\n",
    "\n",
    "email: {email}\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_prompt = ChatPromptTemplate.from_template(template=email_template_revised)\n",
    "messages = updated_prompt.format_messages(email=email_response, format_instructions=format_instructions)\n",
    "format_response = chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.VacationInfo'>\n",
      "Cities: Amsterdam\n",
      "Cities: Brussels\n"
     ]
    }
   ],
   "source": [
    "vacation = pydantic_parser.parse(format_response.content)\n",
    "print(type(vacation))\n",
    "# print(vacation.cities_to_visit)\n",
    "for item in vacation.cities_to_visit:\n",
    "    print(f\"Cities: {item}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory Hands on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "\n",
      "Sure! BTS (also known as the Bangtan Boys) is a South Korean boy band that debuted in 2013 under Big Hit Entertainment. The group consists of seven members: RM, Jin, Suga, J-Hope, Jimin, V, and Jungkook. They are known for their powerful rap and vocal skills, as well as their socially conscious lyrics that tackle topics such as mental health, societal pressures, and self-love. BTS has gained a huge following worldwide, known as the BTS ARMY, and have broken numerous records in the music industry. They have also collaborated with many international artists and have won several awards, including multiple Billboard Music Awards and a Grammy nomination.\n",
      "\n",
      "Seventeen is also a South Korean boy band that debuted in 2015 under Pledis Entertainment. The group consists of thirteen members: S.Coups, Jeonghan, Joshua, Jun, Hoshi, Wonwoo, Woozi, DK, Mingyu, The8, Seungkwan, Vernon, and Dino. Seventeen is known for their self-produced music, intricate choreography, and diverse concept styles. They have a unique structure within the group, with members being divided into three sub-units: hip-hop, vocal, and performance\n"
     ]
    }
   ],
   "source": [
    "print(llm.predict(\"Hi! My favourite bands are BTS and Seventeen. Can you tell me about them?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "I'm sorry, I am not able to determine your personal preferences or favorites as I am an AI and do not have access to that information. \n"
     ]
    }
   ],
   "source": [
    "print(llm.predict(\"Great! What's my favourite band?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory()\n",
    "conversation = ConversationChain(\n",
    "    llm = llm,\n",
    "    memory = memory,\n",
    "    verbose = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi! My favourite bands are BTS and Seventeen. Can you tell me about them?\n",
      "AI:  Hi there! BTS, also known as Bangtan Boys, is a South Korean boy band that debuted in 2013. They have seven members: RM, Jin, Suga, J-Hope, Jimin, V, and Jungkook. They are known for their energetic performances and socially conscious lyrics. They have released several albums, including \"Map of the Soul: Persona\" and \"Love Yourself: Tear,\" which have both achieved global success. As for Seventeen, they are a 13-member boy group also from South Korea. They debuted in 2015 and are known for their self-produced music and synchronized choreography. Some of their popular songs include \"Don't Wanna Cry\" and \"Very Nice.\" Both BTS and Seventeen have dedicated fan bases and have won numerous awards for their music. Is there anything else you would like to know about them?\n",
      "Human: Hi! My favourite bands are BTS and Seventeen. Can you tell me about them?\n",
      "AI:  Sure! As I mentioned, BTS has seven members while Seventeen has 13 members. They both have unique concepts and styles, with BTS often addressing social issues in their music and Seventeen showcasing their impressive dancing abilities. Both groups have also gained international recognition, with BTS even becoming the first K-pop group to perform at the Grammy Awards in 2020. Did you have any specific questions about their music or members?\n",
      "Human: Great! What's my favourite band?\n",
      "AI:  I do not have enough information to accurately determine your favorite band. Can you tell me more about your preferences and tastes in music?\n",
      "Human: Hi! My name is Siddhi\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi! My favourite bands are BTS and Seventeen. Can you tell me about them?\n",
      "AI:  Hi there! BTS, also known as Bangtan Boys, is a South Korean boy band that debuted in 2013. They have seven members: RM, Jin, Suga, J-Hope, Jimin, V, and Jungkook. They are known for their energetic performances and socially conscious lyrics. They have released several albums, including \"Map of the Soul: Persona\" and \"Love Yourself: Tear,\" which have both achieved global success. As for Seventeen, they are a 13-member boy group also from South Korea. They debuted in 2015 and are known for their self-produced music and synchronized choreography. Some of their popular songs include \"Don't Wanna Cry\" and \"Very Nice.\" Both BTS and Seventeen have dedicated fan bases and have won numerous awards for their music. Is there anything else you would like to know about them?\n",
      "Human: Hi! My favourite bands are BTS and Seventeen. Can you tell me about them?\n",
      "AI:  Sure! As I mentioned, BTS has seven members while Seventeen has 13 members. They both have unique concepts and styles, with BTS often addressing social issues in their music and Seventeen showcasing their impressive dancing abilities. Both groups have also gained international recognition, with BTS even becoming the first K-pop group to perform at the Grammy Awards in 2020. Did you have any specific questions about their music or members?\n",
      "Human: Great! What's my favourite band?\n",
      "AI:  I do not have enough information to accurately determine your favorite band. Can you tell me more about your preferences and tastes in music?\n",
      "Human: Hi! My name is Siddhi\n",
      "AI:  Hello Siddhi, it's nice to meet you! Is there anything else you would like to know about BTS and Seventeen?\n",
      "Human: Great! What's my name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Your name is Siddhi, as you mentioned earlier. Did you have any other questions?'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Hi! My name is Siddhi\")\n",
    "conversation.predict(input=\"Great! What's my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory => Human: Hi! My favourite bands are BTS and Seventeen. Can you tell me about them?\n",
      "AI:  Hi there! BTS, also known as Bangtan Boys, is a South Korean boy band that debuted in 2013. They have seven members: RM, Jin, Suga, J-Hope, Jimin, V, and Jungkook. They are known for their energetic performances and socially conscious lyrics. They have released several albums, including \"Map of the Soul: Persona\" and \"Love Yourself: Tear,\" which have both achieved global success. As for Seventeen, they are a 13-member boy group also from South Korea. They debuted in 2015 and are known for their self-produced music and synchronized choreography. Some of their popular songs include \"Don't Wanna Cry\" and \"Very Nice.\" Both BTS and Seventeen have dedicated fan bases and have won numerous awards for their music. Is there anything else you would like to know about them?\n",
      "Human: Hi! My favourite bands are BTS and Seventeen. Can you tell me about them?\n",
      "AI:  Sure! As I mentioned, BTS has seven members while Seventeen has 13 members. They both have unique concepts and styles, with BTS often addressing social issues in their music and Seventeen showcasing their impressive dancing abilities. Both groups have also gained international recognition, with BTS even becoming the first K-pop group to perform at the Grammy Awards in 2020. Did you have any specific questions about their music or members?\n",
      "Human: Great! What's my favourite band?\n",
      "AI:  I do not have enough information to accurately determine your favorite band. Can you tell me more about your preferences and tastes in music?\n",
      "Human: Hi! My name is Siddhi\n",
      "AI:  Hello Siddhi, it's nice to meet you! Is there anything else you would like to know about BTS and Seventeen?\n",
      "Human: Great! What's my name?\n",
      "AI:  Your name is Siddhi, as you mentioned earlier. Did you have any other questions?\n"
     ]
    }
   ],
   "source": [
    "print(f\"memory => {memory.buffer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_ai = OpenAI(temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    input_variables = [\"language\"],\n",
    "    template = \"How do you say good morning in {language}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The most common way to say good morning in Korean is \"안녕하세요\" (annyeonghaseyo). However, there are also other ways to greet someone in the morning, such as \"좋은 아침입니다\" (joheun achimimnida) or \"좋은 아침이에요\" (joheun achimieyo).\n"
     ]
    }
   ],
   "source": [
    "chain = LLMChain(llm=open_ai, prompt=prompt)\n",
    "print(chain.run(language=\"Korean\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\" \n",
    " As a children's book writer, please come up with a simple and short (90 words)\n",
    " lullaby based on the location\n",
    " {location}\n",
    " and the main character {name}\n",
    " \n",
    " STORY:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(input_variables=[\"location\", \"name\"], template=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m \n",
      " As a children's book writer, please come up with a simple and short (90 words)\n",
      " lullaby based on the location\n",
      " Spain\n",
      " and the main character Maya\n",
      " \n",
      " STORY:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\"Maya, mi niña, close your eyes\n",
      "Underneath the Spanish skies\n",
      "The stars above twinkle bright\n",
      "As you drift off into the night\n",
      "\n",
      "Dream of castles and flamenco dance\n",
      "As the moonbeams cast their magic trance\n",
      "Maya, mi amor, sleep tight\n",
      "In this land of Spanish delight\n",
      "\n",
      "Let the guitar strum a gentle tune\n",
      "As you rest beneath the Spanish moon\n",
      "Maya, mi querida, rest your head\n",
      "In this beautiful land where dreams are fed\n",
      "\n",
      "So sleep, my little one, with a smile\n",
      "For in Spain, life is always worthwhile\n",
      "Maya, mi niña, buenos noches\n",
      "Until the morning, sleep and recharge\" \n"
     ]
    }
   ],
   "source": [
    "chain_story = LLMChain(llm=open_ai, prompt=prompt, verbose=True)\n",
    "story = chain_story({\"location\": \"Spain\", \"name\": \"Maya\"})\n",
    "print(story['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_story = LLMChain(llm=open_ai, prompt=prompt, output_key=\"ogstory\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_update = \"\"\"Translate the {ogstory} into {language}.  Make sure \n",
    "the language is simple and fun.\n",
    "\n",
    "TRANSLATION: \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_translate = PromptTemplate(input_variables=[\"ogstory\", \"language\"], template=template_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_translate = LLMChain(llm=open_ai, prompt=prompt_translate, output_key=\"translated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_chain = SequentialChain(\n",
    "    chains = [chain_story, chain_translate],\n",
    "    input_variables= [\"location\", \"name\", \"language\"],\n",
    "    output_variables= [\"ogstory\", \"translated\"],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m \n",
      " As a children's book writer, please come up with a simple and short (90 words)\n",
      " lullaby based on the location\n",
      " Mumbai\n",
      " and the main character Karina\n",
      " \n",
      " STORY:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "English Version ==> \n",
      "In Mumbai's bustling streets,\n",
      "Lives a little girl named Karina.\n",
      "She loves to dance and sing,\n",
      "But at night, she needs some rest.\n",
      "\n",
      "So her mother sings a lullaby,\n",
      "Softly to her daughter's ears.\n",
      "The city's noises fade away,\n",
      "As Karina drifts off to sleep.\n",
      "\n",
      "The stars above shine so bright,\n",
      "As the moon watches over Mumbai.\n",
      "Karina dreams of adventures,\n",
      "In this magical city of lights.\n",
      "\n",
      "So sleep now, my dear Karina,\n",
      "In the heart of Mumbai's embrace.\n",
      "Tomorrow is a new day,\n",
      "Full of wonders and grace.\n",
      "\n",
      "Goodnight, my little one,\n",
      "Sleep tight in Mumbai's embrace. \n",
      " \n",
      "\n",
      "Translated Version ==> मुंबई की भीड़भाड़ वाली सड़कों में,\n",
      "एक छोटी सी लड़की का नाम है करीना।\n",
      "वह नाचने और गाने से बहुत प्यार करती है,\n",
      "लेकिन रात में उसे आराम की ज़रूरत होती है।\n",
      "\n",
      "इसलिए उसकी माँ उसे एक लोरी गाती है,\n",
      "अपनी बेटी के कानों में धीरे से।\n",
      "शहर की शोरगुल से दूर हो जाती है,\n",
      "जब क \n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = overall_chain({\"location\": \"Mumbai\", \"name\": \"Karina\", \"language\": \"Hindi\"})\n",
    "print(f\"English Version ==> {response['ogstory']} \\n \\n\")\n",
    "print(f\"Translated Version ==> {response['translated']} \\n \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Router Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.router.multi_prompt_prompt import MULTI_PROMPT_ROUTER_TEMPLATE\n",
    "from langchain.chains.router.llm_router import LLMRouterChain, RouterOutputParser\n",
    "from langchain.chains.router import MultiPromptChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "biology_template = \"\"\"You are a very smart biology professor. \n",
    "You are great at answering questions about biology in a concise and easy to understand manner. \n",
    "When you don't know the answer to a question you admit that you don't know.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "math_template = \"\"\"You are a very good mathematician. You are great at answering math questions. \n",
    "You are so good because you are able to break down hard problems into their component parts, \n",
    "answer the component parts, and then put them together to answer the broader question.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "astronomy_template = \"\"\"You are a very good astronomer. You are great at answering astronomy questions. \n",
    "You are so good because you are able to break down hard problems into their component parts, \n",
    "answer the component parts, and then put them together to answer the broader question.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "travel_agent_template = \"\"\"You are a very good travel agent with a large amount\n",
    "of knowledge when it comes to getting people the best deals and recommendations\n",
    "for travel, vacations, flights and world's best destinations for vacation. \n",
    "You are great at answering travel, vacation, flights, transportation, tourist guides questions. \n",
    "You are so good because you are able to break down hard problems into their component parts, \n",
    "answer the component parts, and then put them together to answer the broader question.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_infos = [\n",
    "    {\n",
    "        \"name\": \"Biology\",\n",
    "        \"description\": \"Good for answering biology related questions\",\n",
    "        \"prompt_template\": biology_template,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"math\",\n",
    "        \"description\": \"Good for answering math related questions\",\n",
    "        \"prompt_template\": math_template,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"astronomy\",\n",
    "        \"description\": \"Good for answering astronomy questions\",\n",
    "        \"prompt_template\": astronomy_template,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"travel_agent\",\n",
    "        \"description\": \"Good for answering travel, tourism and vacation questions\",\n",
    "        \"prompt_template\": travel_agent_template,\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_chains = {}\n",
    "for info in prompt_infos:\n",
    "    name = info[\"name\"]\n",
    "    prompt_template = info[\"prompt_template\"]\n",
    "    prompt = ChatPromptTemplate.from_template(template=prompt_template)\n",
    "    chain = LLMChain(llm=chat, prompt = prompt)\n",
    "    destination_chains[name] = chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_prompt = ChatPromptTemplate.from_template(\"{input}\")\n",
    "default_chain = LLMChain(llm=chat, prompt=default_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos]\n",
    "destinations_str =  \"\\n\".join(destinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(destinations=destinations_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "router_prompt = PromptTemplate(\n",
    "    template = router_template,\n",
    "    input_variables=[\"input\"],\n",
    "    output_parser=RouterOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "router_chain = LLMRouterChain.from_llm(\n",
    "    llm=chat,\n",
    "    prompt=router_prompt,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = MultiPromptChain(\n",
    "    router_chain=router_chain,\n",
    "    destination_chains=destination_chains,\n",
    "    default_chain=default_chain,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "astronomy: {'input': 'How old are the stars?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Stars can vary greatly in age depending on their size and type. \n",
      "\n",
      "For example, smaller stars like red dwarfs can have lifespans of tens to hundreds of billions of years, while larger stars like blue giants may only live for a few million years. \n",
      "\n",
      "On average, most stars in our galaxy are thought to be around 10 billion years old, as the Milky Way itself is estimated to be around 13.6 billion years old. \n",
      "\n",
      "However, there are also much older stars known as Population II stars, which are believed to be remnants from the early universe and can be as old as 13.8 billion years. \n",
      "\n",
      "So, in general, stars can range in age from a few million years to over 13 billion years old.\n"
     ]
    }
   ],
   "source": [
    "response = chain.run(\"How old as the stars?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "travel_agent: {'input': 'I need to plan a vacation to Kenya for a family of four. Can you help me with this trip?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Of course! I would be happy to help you plan a vacation to Kenya for your family of four. Kenya is a beautiful country with so much to offer in terms of wildlife, culture, and natural beauty.\n",
      "\n",
      "First, I would recommend looking into the best time to visit Kenya based on your preferences. The dry season from June to October is typically the best time for wildlife viewing, while the wet season from November to May is great for bird watching and lush landscapes.\n",
      "\n",
      "Next, I would suggest considering what activities and attractions you would like to experience in Kenya. From going on safari in the Maasai Mara or Amboseli National Park, to visiting the coastal city of Mombasa or exploring the Great Rift Valley, there are so many options to choose from.\n",
      "\n",
      "In terms of accommodations, there are a variety of options ranging from luxury lodges and tented camps to budget-friendly guesthouses and hotels. I can help you find the best accommodations that fit your budget and preferences.\n",
      "\n",
      "When it comes to transportation, I can assist you in booking flights to Kenya, as well as arranging for ground transportation such as car rentals or private transfers.\n",
      "\n",
      "Lastly, I can provide you with recommendations for tour guides and excursions to ensure that you make the most of your time in Kenya and have a memorable vacation experience.\n",
      "\n",
      "Feel free to ask me any specific questions or provide me with more details about your preferences, and I will tailor a personalized itinerary for your family's trip to Kenya.\n"
     ]
    }
   ],
   "source": [
    "response = chain.run(\"I need to go to Kenya for vacation, a family of four. Can you help me plan this trip?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "None: {'input': 'Tell me about Attaca by Seventeen'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Attaca is a song by the South Korean boy group Seventeen. It is a track from their seventh mini album \"Heng:garæ,\" which was released on June 22, 2020. The song is a high-energy dance track with a catchy chorus and powerful rap verses. The lyrics talk about breaking down barriers and pushing forward with determination and strength. The members of Seventeen showcase their impressive vocal and rap skills in this song, making it a fan favorite among their discography. Attaca has been praised for its dynamic production and energetic performance, solidifying Seventeen's reputation as one of the top K-pop groups in the industry.\n"
     ]
    }
   ],
   "source": [
    "response = chain.run(\"Tell me about Attaca by Seventeen\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF Loading & Splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PDF Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(\"./data/react-paper.pdf\")\n",
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    }
   ],
   "source": [
    "print(len(pages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Published as a conference paper at ICLR 2023\n",
      "REAC T: S YNERGIZING REASONING AND ACTING IN\n",
      "LANGUAGE MODELS\n",
      "Shunyu Yao∗*,1, Jeffrey Zhao2, Dian Yu2, Nan Du2, Izhak Shafran2, Karthik Narasimhan1, Yuan Cao2\n",
      "1Department of Computer Science, Princeton University\n",
      "2Google Research, Brain team\n",
      "1{shunyuy,karthikn}@princeton.edu\n",
      "2{jeffreyzhao,dianyu,dunan,izhak,yuancao}@google.com\n",
      "ABSTRACT\n",
      "While large language models (LLMs) have demonstrated impressive performance\n",
      "across tasks in language understanding and interactive decision making, their\n",
      "abilities for reasoning (e.g. chain-of-thought prompting) and acting (e.g. action\n",
      "plan generation) have primarily been studied as separate topics. In this paper, we\n",
      "{'source': './data/react-paper.pdf', 'page': 0}\n"
     ]
    }
   ],
   "source": [
    "page = pages[0]\n",
    "print(page.page_content[0:700])\n",
    "print(page.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/i-have-a-dream.txt\") as paper:\n",
    "    speech = paper.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter(\n",
    "    chunk_size = 50,\n",
    "    chunk_overlap = 20,\n",
    "    length_function = len,\n",
    "    add_start_index=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='﻿As far as black Americans were concerned, the nation’s response to Brown was agonizingly slow, and neither state legislatures nor the Congress seemed willing to help their cause along. Finally, President John F. Kennedy recognized that only a strong civil rights bill would put teeth into the drive to secure equal protection of the laws for African Americans. On June 11, 1963, he proposed such a bill to Congress, asking for legislation that would provide “the kind of equality of treatment which we would want for ourselves.” Southern representatives in Congress managed to block the bill in committee, and civil rights leaders sought some way to build political momentum behind the measure.\n",
      "A. Philip Randolph, a labor leader and longtime civil rights activist, called for a massive march on Washington to dramatize the issue. He welcomed the participation of white groups as well as black in order to demonstrate the multiracial backing for civil rights. The various elements of the civil rights movement, many of which had been wary of one another, agreed to participate. The National Association for the Advancement of Colored People, the Congress of Racial Equality, the Southern Christian Leadership Conference, the Student Non-violent Coordinating Committee and the Urban League all managed to bury their differences and work together. The leaders even agreed to tone down the rhetoric of some of the more militant activists for the sake of unity, and they worked closely with the Kennedy administration, which hoped the march would, in fact, lead to passage of the civil rights bill.\n",
      "On August 28, 1963, under a nearly cloudless sky, more than 250,000 people, a fifth of them white, gathered near the Lincoln Memorial in Washington to rally for “jobs and freedom.” The roster of speakers included speakers from nearly every segment of society — labor leaders like Walter Reuther, clergy, film stars such as Sidney Poitier and Marlon Brando and folksingers such as Joan Baez. Each of the speakers was allotted fifteen minutes, but the day belonged to the young and charismatic leader of the Southern Christian Leadership Conference.\n",
      "Dr. Martin Luther King Jr. had originally prepared a short and somewhat formal recitation of the sufferings of African Americans attempting to realize their freedom in a society chained by discrimination. He was about to sit down when gospel singer Mahalia Jackson called out, “Tell them about your dream, Martin! Tell them about the dream!” Encouraged by shouts from the audience, King drew upon some of his past talks, and the result became the landmark statement of civil rights in America — a dream of all people, of all races and colors and backgrounds, sharing in an America marked by freedom and democracy.\n",
      "For further reading: Herbert Garfinkel, When Negroes March: The March on Washington…(1969); Taylor Branch, Parting the Waters: America in the King Years, 1954-1963 (1988); Stephen B. Oates, Let the Trumpet Sound: The Life of Martin Luther King Jr. (1982).“I HAVE A DREAM” (1963)\n",
      "I am happy to join with you today in what will go down in history as the greatest demonstration for freedom in the history of our nation.\n",
      "Five score years ago, a great American, in whose symbolic shadow we stand today, signed the Emancipation Proclamation. This momentous decree came as a great beacon of hope to millions of slaves, who had been seared in the flames of whithering injustice. It came as a joyous daybreak to end the long night of their captivity. But one hundred years later, the colored America is still not free. One hundred years later, the life of the colored American is still sadly crippled by the manacle of segregation and the chains of discrimination.\n",
      "One hundred years later, the colored American lives on a lonely island of poverty in the midst of a vast ocean of material prosperity. One hundred years later, the colored American is still languishing in the corners of American society and finds himself an exile in his own land So we have come here today to dramatize a shameful condition.\n",
      "In a sense we have come to our Nation’s Capital to cash a check. When the architects of our great republic wrote the magnificent words of the Constitution and the Declaration of Independence, they were signing a promissory note to which every American was to fall heir.\n",
      "This note was a promise that all men, yes, black men as well as white men, would be guaranteed the inalienable rights of life liberty and the pursuit of happiness.\n",
      "It is obvious today that America has defaulted on this promissory note insofar as her citizens of color are concerned. Instead of honoring this sacred obligation, America has given its colored people a bad check, a check that has come back marked “insufficient funds.”\n",
      "But we refuse to believe that the bank of justice is bankrupt. We refuse to believe that there are insufficient funds in the great vaults of opportunity of this nation. So we have come to cash this check, a check that will give us upon demand the riches of freedom and security of justice.\n",
      "We have also come to his hallowed spot to remind America of the fierce urgency of Now. This is not time to engage in the luxury of cooling off or to take the tranquilizing drug of gradualism.\n",
      "Now is the time to make real the promise of democracy.\n",
      "Now it the time to rise from the dark and desolate valley of segregation to the sunlit path of racial justice.\n",
      "Now it the time to lift our nation from the quicksand of racial injustice to the solid rock of brotherhood.\n",
      "Now is the time to make justice a reality to all of God’s children.\n",
      "I would be fatal for the nation to overlook the urgency of the moment and to underestimate the determination of it’s colored citizens. This sweltering summer of the colored people’s legitimate discontent will not pass until there is an invigorating autumn of freedom and equality. Nineteen sixty-three is not an end but a beginning. Those who hope that the colored Americans needed to blow off steam and will now be content will have a rude awakening if the nation returns to business as usual.\n",
      "There will be neither rest nor tranquility in America until the colored citizen is granted his citizenship rights. The whirlwinds of revolt will continue to shake the foundations of our nation until the bright day of justice emerges.\n",
      "We can never be satisfied as long as our bodies, heavy with the fatigue of travel, cannot gain lodging in the motels of the highways and the hotels of the cities.\n",
      "We cannot be satisfied as long as the colored person’s basic mobility is from a smaller ghetto to a larger one.\n",
      "We can never be satisfied as long as our children are stripped of their selfhood and robbed of their dignity by signs stating “for white only.”\n",
      "We cannot be satisfied as long as a colored person in Mississippi cannot vote and a colored person in New York believes he has nothing for which to vote.\n",
      "No, no we are not satisfied and we will not be satisfied until justice rolls down like waters and righteousness like a mighty stream.\n",
      "I am not unmindful that some of you have come here out of your trials and tribulations. Some of you have come from areas where your quest for freedom left you battered by storms of persecutions and staggered by the winds of police brutality.\n",
      "You have been the veterans of creative suffering. Continue to work with the faith that unearned suffering is redemptive.\n",
      "Go back to Mississippi, go back to Alabama, go back to South Carolina go back to Georgia, go back to Louisiana, go back to the slums and ghettos of our modern cities, knowing that somehow this situation can and will be changed.\n",
      "Let us not wallow in the valley of despair. I say to you, my friends, we have the difficulties of today and tomorrow.\n",
      "I still have a dream. It is a dream deeply rooted in the American dream.\n",
      "I have a dream that one day this nation will rise up and live out the true meaning of its creed. We hold these truths to be self-evident that all men are created equal.\n",
      "I have a dream that one day out in the red hills of Georgia the sons of former slaves and the sons of former slaveowners will be able to sit down together at the table of brotherhood.\n",
      "I have a dream that one day even the state of Mississippi, a state sweltering with the heat of oppression, will be transformed into an oasis of freedom and justice.\n",
      "I have a dream that my four little children will one day live in a nation where they will not be judged by the color of their skin but by their character.\n",
      "I have a dream today.\n",
      "I have a dream that one day down in Alabama, with its vicious racists, with its governor having his lips dripping with the words of interposition and nullification; that one day right down in Alabama little black boys and black girls will be able to join hands with little white boys and white girls as sisters and brothers.\n",
      "I have a dream today.\n",
      "I have a dream that one day every valley shall be engulfed, every hill shall be exalted and every mountain shall be made low, the rough places will be made plains and the crooked places will be made straight and the glory of the Lord shall be revealed and all flesh shall see it together.\n",
      "This is our hope. This is the faith that I will go back to the South with. With this faith we will be able to hew out of the mountain of despair a stone of hope.\n",
      "With this faith we will be able to transform the jangling discords of our nation into a beautiful symphony of brotherhood.\n",
      "With this faith we will be able to work together, to pray together, to struggle together, to go to jail together, to climb up for freedom together, knowing that we will be free one day.\n",
      "This will be the day when all of God’s children will be able to sing with new meaning “My country ’tis of thee, sweet land of liberty, of thee I sing. Land where my father’s died, land of the Pilgrim’s pride, from every mountainside, let freedom ring!”\n",
      "And if America is to be a great nation, this must become true. So let freedom ring from the hilltops of New Hampshire. Let freedom ring from the mighty mountains of New York.\n",
      "Let freedom ring from the heightening Alleghenies of Pennsylvania.\n",
      "Let freedom ring from the snow-capped Rockies of Colorado.\n",
      "Let freedom ring from the curvaceous slopes of California.\n",
      "But not only that, let freedom, ring from Stone Mountain of Georgia.\n",
      "Let freedom ring from every hill and molehill of Mississippi and every mountainside.\n",
      "When we let freedom ring, when we let it ring from every tenement and every hamlet, from every state and every city, we will be able to speed up that day when all of God’s children, black men and white men, Jews and Gentiles, Protestants and Catholics, will be able to join hands and sing in the words of the old spiritual, “Free at last, free at last. Thank God Almighty, we are free at last.' metadata={'start_index': 0}\n"
     ]
    }
   ],
   "source": [
    "texts = text_splitter.create_documents([speech])\n",
    "print(texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 50,\n",
    "    chunk_overlap = 20,\n",
    "    length_function = len,\n",
    "    add_start_index=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = text_splitter.create_documents([speech])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "353\n",
      "Doc 1: page_content='﻿As far as black Americans were concerned, the' metadata={'start_index': 0}\n",
      "Doc 2: page_content='were concerned, the nation’s response to Brown' metadata={'start_index': 27}\n"
     ]
    }
   ],
   "source": [
    "print(len(docs))\n",
    "print(f\"Doc 1: {docs[0]}\")\n",
    "print(f\"Doc 2: {docs[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Python can be easy to pick up whether you're a\", \"up whether you're a professional or a beginner.\"]\n"
     ]
    }
   ],
   "source": [
    "s1 = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "s = \"Python can be easy to pick up whether you're a professional or a beginner.\"\n",
    "\n",
    "text = text_splitter.split_text(s)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Load the file\n",
    "loader = PyPDFLoader(\"./data/react-paper.pdf\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96\n"
     ]
    }
   ],
   "source": [
    "#2. Split the document into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1500,\n",
    "    chunk_overlap = 150\n",
    ")\n",
    "splits = text_splitter.split_documents(docs)\n",
    "print(len(splits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embed1 == [-0.008174207879591734, -0.007511803310590743, -0.00995655437174355, -0.024788951157780095, -0.012790553094547429, 0.006654775143594856, -0.0015151649503578363, -0.03783217392596492, -0.014422662356334227, -0.026250339680779597, 0.017154227704543168, 0.046327340706031526, 0.0035646922858117093, 0.004240754467349556, -0.032287098019987186, -0.004592443287070655, 0.03955306057962428, 0.005261676778755394, 0.00789422251521935, -0.015501631209043845, -0.023723641081760536, 0.0053197228543978925, 0.014873371253461594, -0.012141805905252653, -0.006781109980413554, 0.004384161843708263, 0.01238764712186758, -0.013364181668659696, 0.005620194986821522, 0.0009731200272425828, 0.009881435756561042, -0.01653962559432841, -0.017796145505492914, -0.03922527229080438, -0.02947358559957327, -0.0003316290630643998, 0.011465743956545447, -0.007361567477209569, 0.02073257760289173, -0.01391732300905944, 0.009451215024468763, 0.009806318072701095, -0.013371010125682163, 0.011916451922350252, -0.0024532866324308905, 0.010496037866775797, -0.02174325629744131, -0.007498145465223247, -0.006275770167477485, 0.012414962812602572, 0.006675261911646101, 0.006910859045743484, -0.005743115129467705, 0.014094874998836887, -0.004991935031239271, 0.005606537141454026, 0.008672718769844056, -0.012032543142312686, 0.013493930733989627, -0.0006628312893572352, 0.012333015740397597, 0.004288556926135792, -0.006429420695031173, 0.025089423755865006, 0.007989827432791821, -0.005070467409271732, -0.004800725196094328, 1.3271030909728613e-05, -0.003964183797149684, 0.003933453412242179, 0.04176562594122325, 0.01660791388984333, 0.02151107385751644, -0.009082453199546371, -0.00699280611794846, -0.00045540308298052133, -0.018301484852767703, 0.011534033183382926, 0.0008869049947755849, -0.011042350750153073, 0.035728867602015664, -0.03307925118865682, -0.013268576751087224, 0.009239517955611294, 0.021852519060381277, 0.007409369935995805, -0.004950961495136783, 0.009806318072701095, -0.012059858833047677, 0.009273663034691315, 0.015201158610958934, 0.024051429370580437, -0.01398561223589692, 0.042421202518863055, -0.01155451948577289, 0.020377473623336837, -0.01321394536961724, 0.022180307349201178, -0.001471630626456603, -0.05763601804386693, 0.004575371213191926, 0.0058182332789889326, -0.04826675288557083, -0.00939658364299878, -0.003011550246920045, -0.0016406462300487248, 0.016894729573883306, 0.0038037041140816076, 0.020787208984361715, -0.005821647507500166, -0.0027537587648545202, 0.05392109155448852, 0.020828181589141643, -0.030347685840447884, 0.007252304714269601, -0.0036056655890835568, 0.0002332500411708059, -0.028544853977228668, 0.00447635206710822, -0.019639951836137183, 0.019161928179597384, 0.013896836706669477, 0.03843311912213474, 0.004401233917586993, 0.02274027807794595, 0.01761859444703803, -0.010099961282440976, 0.008071774504996796, -0.013562219960827107, 0.015965996088893583, 0.02767075187370893, 0.0037012705066560283, 0.009225860110243799, 0.009300978725426307, -0.0031310563938856347, 0.026564469192909442, -0.041028104154023595, -0.0022142748041609926, -0.0031259345854575036, -0.06692334171789342, -0.0025966940087895976, 0.018970718344452443, -0.02024089516966188, 0.017167884618588102, -0.0024720662862265175, 0.023764615549185585, 0.01731812184895312, 0.002560842048284601, 0.009143913969361385, 0.005425570923165346, 0.009130256123993888, -0.0010712855579908193, 0.030101844623832957, -0.016293784377713484, -0.004797310967583094, 0.03012916031456795, -0.000863003765382467, 0.01354856211545961, -1.6938903847351672e-05, -0.013842205325199492, 0.001397366150478504, -0.004141735321265851, 0.01720885908601315, -0.011827676393122807, 0.002014529164907325, 0.018533667292692572, 0.023054407590075796, 0.0030439877460831685, -0.01729080615821813, 0.0036363957411604227, -0.02147009939009139, 0.018929745739672516, -0.008679547226866523, 0.013207115981272213, -0.010277513272218423, 0.006699162908208578, -0.012292042204295108, -0.00779178914062441, -0.01593868039815859, -0.02336853710220564, -0.015638209662718804, 0.00865906092447656, 0.01551528905441134, 0.027151755612389205, -0.003783217346030364, 0.007429856704047048, 0.02000871272973701, -0.01879316728599756, -0.0043909907663920115, -0.007334251786474577, 0.009615108237556153, 0.025198686518804973, 0.021210601259431527, -0.02406508628462537, -0.6756799127418118, -0.027383938052314077, -0.015255789992428917, -0.007593750382795719, 0.014668503572949155, 0.02095110312877167, 0.0023320736040403247, 0.004483180989791969, 0.001397366150478504, -0.007382054245260813, -0.011083324286255561, 0.006180165715566294, 0.006945003659162224, -0.009765344536598606, -0.009478529783881192, -0.009075624742523904, -0.008747836453704002, -0.01588405087933373, -0.02060965792590683, 0.021005734510241653, 0.0051626576326716895, 0.004513910909038194, -0.004076860788600886, -0.012913472771532332, 0.006429420695031173, -0.009212202264876302, 0.01134965180526045, -0.027930251867013912, 0.02317732912970582, 0.02125157572685658, -0.014368031906186806, 0.024693347171530183, -0.003991499022223396, -0.01839708883901761, 0.049058906054240466, 0.01731812184895312, 0.0025915722003614665, 0.02227591133545109, 0.008092260807386759, 0.038678958476104544, -0.018670245746367532, -0.01882048297673255, 0.01861561436489755, -0.0014511438584053592, -0.027424912519739126, -0.016006970556318632, 0.0008190426629173296, 0.0015313835835240775, 0.006402105469957463, -0.005302650314857882, 0.007566434692060728, -0.008365417714736678, 0.004903159036350547, -0.008399561862494137, 0.0060333441106963535, 0.008870757062011465, 0.025034792374395022, -0.017154227704543168, 0.003317144187771806, 0.008433706941574158, -0.0061050475660450665, 0.005432399845849094, -0.004370503998340767, -0.01973555582238709, -0.013569048417849575, 0.007545947924009483, -0.017536647374833052, 0.0003154103716904984, 0.025485500340199824, 0.010270683883873396, 0.006477223153817409, 0.0024908457071915044, -0.030484264294122845, -0.0014596800117600442, 0.00449342414098695, 0.027534173420033968, 0.00497486249169926, -0.010830654612618167, -8.087992934436227e-05, -0.020172606874146962, -0.006565999148706133, -0.0026205950053520754, -0.025239659123584897, -0.010905773227800675, 0.018506351601957582, -0.01321394536961724, -0.023587062628085576, -0.0007776424064585977, 0.015897707793378665, 0.008754665842049031, 0.004858771271736826, 0.03152225867940741, -0.011295021355113028, 0.015378710600736381, -0.014968976171034066, 0.004729021740745615, -0.005838720047040177, 0.002531819243293992, 0.014053901462734398, -0.03425382402761635, -0.0011839626658573406, -0.005951397038491377, 0.008741007996681534, -0.002835705837059496, 0.016498652989548487, 0.015119211538753959, -0.014286084833981829, 0.018001012254682792, 0.03548302824804586, -0.015597235195293754, 0.009628766082923648, -0.0076893553003681905, -0.010359460344423399, 0.00023410364195435937, 0.012660803097894937, -0.030183791696037934, 0.009676569007371164, 0.004503667757843213, 0.01708593940902825, -0.01720885908601315, -0.01105600859552057, 0.02301343498529587, 0.012688118788629929, -0.004722192818061867, 0.007457172394782041, 0.0002923628158405091, -0.02447482164565025, 0.0012445692964679438, -0.004872429117104322, -0.008372246171759145, 0.006630873681371098, -0.013794402400751976, 0.008829783525908979, -0.011677440094080354, 0.004213438776614564, 0.006166507870198798, 0.02540355326799485, 0.012961275695979848, 0.01711325509976324, -0.0028305840286313648, -0.019803845980547134, 0.009492187629248689, 0.0030525237830225332, 0.006869885975302277, 0.019585320454667196, 0.0006530147421031777, -0.005999199497277613, -0.02480260993447015, 0.0076893553003681905, 0.00022834175299186205, -0.013555390572482078, -0.009294149337081278, 0.024188007824255398, 0.01836977314828262, 0.034991345814816006, -0.02414703335683035, -0.002967162482306324, -0.01653962559432841, -0.01690838648792824, -0.005971883806542622, 0.0072591336369533495, 0.03045694860338785, -0.00431245792269827, -0.01182084700477778, -0.012565198180322465, -0.022508095638021083, 0.008686376615211551, 0.028626801049433645, -0.029555532671778243, -0.0338440905292366, 0.00024221298764131008, -0.021893493527806326, -0.005278749318295405, 0.010571156481958305, 0.009505845474616184, 0.004633416823173143, 0.013241261060352233, -0.03059352705706281, 0.004800725196094328, 0.009867777911193545, 0.02426995489646037, -0.005340209622449137, -0.010776023231148183, -0.0027264433069501687, -0.0010900650953711262, 0.014231453452511846, 0.04190220625754334, 0.020391132400026896, -0.015774788116393764, 0.016525966817638356, -0.013432470895497177, 0.0038549210342097174, 0.0007093532378287782, 0.008706862917601515, -0.0023645108703728075, -0.019790187203857074, -0.001976970090146711, 0.017126912013808174, 0.01607525885183355, 0.02709712423091922, -0.0031378850837387425, 0.008775152144438993, 0.007443514549414544, -0.007573263614744475, 0.018806824200042493, -0.037313177664645196, -0.014559240810009188, -0.005971883806542622, 0.027028834072759182, 0.028572169667963658, -0.001626988384681229, -0.0040188147129583875, -0.016771808034253283, -0.010052159289316022, 0.013439299352519644, 0.020677946221421748, -0.007313765018423333, 0.0035544489017860876, -0.002400362598047164, -0.002175008615144762, -0.011254047819010541, -0.005220703242652907, -0.00305423113010879, 0.020595999149216775, 0.0037320006587328943, 0.018001012254682792, 0.014764108490521627, 0.037012703203915163, 0.0021835446520841266, -0.025663053261299834, -0.026359600581074442, -0.0014758986449262853, 0.005620194986821522, 0.0075322900786419875, 0.002755466111940777, -0.00014202004043580314, 0.025280633591009946, -0.015597235195293754, 0.0337621415943865, 0.014709477109051643, -0.004309043694187036, 0.030975946727352696, 0.00951950331998368, -0.021415468008621406, 0.009178058117118843, -0.0009330001646832236, 0.02276759376868094, 0.017003992336823273, -0.0031344706223968683, 0.013487101345644598, -0.014135848534939375, 0.00344518613884612, -0.018834139890777483, 0.014777766335889122, 0.004623173671978162, -0.016799123724988273, 0.021579362153031356, 0.010318486808320912, 0.019639951836137183, 0.025867920010489712, 0.017099596323073184, 0.007272791482320845, 0.0010072645824536625, -0.002274027761228467, 0.012373989276500083, 0.011868649929225296, 0.010680419244898274, -0.01771419843328794, 0.02327293311595573, -8.658847098637157e-05, -0.014791424181256618, -0.00995655437174355, 0.013289063053477188, -0.015187500765591439, 0.017468357216673013, 0.019667267526872173, -0.001272738544330744, -0.005381182692890343, 0.01607525885183355, -0.0007353884764567373, -0.018970718344452443, -0.04496155989457218, 0.02111499727318162, -0.0018164906399092745, -0.010919431073168171, -0.004148564243949599, -0.02827169706987875, -0.015460657672941356, 0.0011566469751223489, 0.012414962812602572, 0.0015586992742590694, 0.016703519738738362, 0.015460657672941356, 0.01621183730550851, 0.010277513272218423, 0.0023201228729284457, 0.03113984087176265, -0.018970718344452443, 0.00985412006582605, 0.007873736212829385, -0.0036432246638441706, -0.02498016099292504, -0.006576242299901115, -0.022535411328756073, 0.013801231789097005, -0.0095536483990637, -0.013910494552036972, -0.02287685653162091, -0.0019855063599167164, -0.003236904462653088, -0.017236174776748145, 0.014327058370084318, -0.021866177837071333, -0.00699280611794846, -0.020486736386276808, -0.010099961282440976, -0.027875620485543928, -0.005992370574593865, 0.04892232573792038, -0.0006641117414642681, -0.01225106866819262, -0.008420049096206661, -0.03463624369790624, -0.014395346665599235, 0.09281857928176325, 0.005333380699765388, -0.018998034035187433, 0.01375342979597205, 0.0018403918693023923, -0.018520010378647637, -0.02895458747560842, -0.006934760507967242, 0.027247359598639116, 0.011172100746805564, -0.009662911162003669, 0.0022296397637841052, 0.016157205924038527, -0.005756772974835201, 0.0005458861630210317, 0.015009948775813992, -0.021838862146336343, -0.0025045035525590002, 0.009410241488366274, -0.014873371253461594, 0.009533161165351176, -0.0007917270303899979, 0.01535139491000139, 0.002823755338778257, -0.006675261911646101, -0.007074753190153435, 0.0028920443327850962, 0.033980667120266435, 0.012326186352052567, -0.02813511861620379, 0.011049180138498102, 0.016594256975798395, -0.014231453452511846, -0.0036807837386047845, 0.0074161988586795525, 0.002736686690975791, -0.003154957390448112, 0.01408121715346939, 0.023860219535435493, -0.02231688580287614, 0.018438063306442664, 0.025021135460350088, -0.016334758845138537, -0.013767086710016984, 0.007819104831359402, -0.003919795566874683, -0.00374565827126975, 0.018383431924972677, 0.01628012746366855, 0.003235197115566831, 0.03638444417965547, 0.02614107691783963, -0.00845419324396412, 0.006634288375543612, -0.010912601684823142, -0.007095239958204679, 0.020391132400026896, -0.007231817946218358, -0.0016875948988765118, -0.018492694687912647, -0.016730835429473356, -0.013930980854426936, 0.006169922098710032, 0.004708534972694371, -0.002188666460512258, -0.024392874573445272, 0.004875843345615556, -0.022043728895526218, -0.02758880480150395, -0.00912342673564886, -0.013138827685757295, -0.02325927433926567, -0.024215323514990388, 0.010844312457985663, 0.007300107173055837, 0.01158866456485291, 0.018875114358202532, -0.022180307349201178, -0.0024584084408590216, 0.023491458641835664, -0.014272426988614334, -0.024666031480795193, 0.0015527239087031299, -0.03414456126467638, -0.022357858407656063, 0.001751615990828989, -0.0018250267932639593, -0.009997527907846037, 0.00023047579133053328, 0.0021015978127097916, 0.017919065182477815, -0.0030952044333806376, 0.036002024509365585, -0.0067572085181897956, -0.006955247276018486, 0.007798617597646877, 0.0041861230858795725, -0.00719084441011587, -0.0014426077050506741, -0.02980137388839317, 0.01744104152593802, -0.024283611810505305, -0.018998034035187433, -0.0009603157972105554, 0.005715799438732713, 0.0020725747748885424, 0.01907998110739241, 0.028380959832818718, -0.0021084267353935395, -0.013903665163691944, 0.002163057884032883, -0.020787208984361715, -0.004729021740745615, -0.011199416437540556, 0.014053901462734398, 0.01745470030262808, -0.02426995489646037, 0.013275405208109691, 0.019257532165847295, -0.011622808712610368, -0.024829925625205144, -0.016170864700728583, 0.020350157932601847, 0.031249101772057492, -0.007177187030409655, -0.004957790417820531, 0.0006730746733828572, 0.006405519698468696, -0.007457172394782041, 0.007477659162833284, 0.005135341941936698, 0.009294149337081278, -0.015132869384121455, -0.04198415146710319, -0.022193964263246112, -0.011732071475550337, -0.011882307774592793, 0.010762365385780686, -0.0015202866423706472, -0.015542604745146333, -0.03851506433169459, 0.004141735321265851, 0.004800725196094328, -0.02443384904087032, -0.0217705719881763, -0.04392356364664249, -0.031249101772057492, -0.0015569920435881326, 0.004032472558325883, 0.02163399353450134, -0.011281363509745533, 0.009082453199546371, -0.009369267952263786, -0.012394475578890047, -0.016348415759183468, -0.027233702684594182, -0.015037264466548983, -0.00043918442071044995, 0.030948631036617706, 0.020514052077011798, -0.0022159821512472496, 0.0005539955378118124, 0.015528946899778837, -0.0037934607300559855, -0.007539119001325735, 0.00988826514490607, 0.010052159289316022, 0.009034651206421418, -0.0325602549273371, 0.010270683883873396, 0.013084196304287312, -0.0008181890475818612, -0.002019650740504816, -0.001561260062057815, -0.019257532165847295, 0.017345437539688112, 0.007224989023534609, -0.015228474301693926, -0.00010926259559294469, -0.003981255871028414, 0.013637337644687053, -0.0009295857033413496, 0.014846055562726602, 0.014190479916409359, 0.0016406462300487248, -0.005988955880421351, 0.010796510464860708, 0.0013102975026760377, -0.011991569606210197, 0.004336359384922028, 0.018383431924972677, -0.010496037866775797, 0.006951832581845972, -0.02868143243090363, 0.010209224045380943, -0.03611128727230555, -0.011800360702387816, -0.0007592897058498551, -0.002125499042102909, -0.0123193578950301, 0.002075989236230416, 0.03747707180905514, 0.002699127616215177, 0.008802467835173987, -0.0014315107638972438, -0.004288556926135792, 0.00017637799948075, -0.014613872191479171, 0.005131927713425464, -0.016430362831388445, -0.01098772030000565, -0.01675815112020835, -0.056816551047107415, -0.03209588632219712, -0.005650924906067748, 0.0011079910756236248, -0.006945003659162224, 0.010851141846330691, -0.01567918226749873, -0.008358588326391648, -0.014668503572949155, 0.0005057663004616724, 0.028899956094138438, -0.024078745061315427, 0.03070278982000278, 0.030320370149712894, -0.015692841044188787, -0.010564327093613277, 0.011465743956545447, -0.014736792799786635, -0.04665512899485143, 0.0063679608565387225, 0.001321394560244788, -0.008781981532784023, 0.016006970556318632, -0.000150449470045682, 0.0066035579906361065, -0.014245111297879342, -0.029692111125453204, 0.024037770593890378, 0.02313635466228077, -0.006231382402863763, -0.026018155378209604, 0.011076495829233094, -0.013261747362742196, 0.017837118110272842, -0.012257897125215087, -0.007061095344785939, -0.036411761733035584, -0.006449907463082417, -0.019148269402907328, 0.012435449114992534, -0.02110133849649156, 0.014764108490521627, 0.00323007553996934, -0.0033376309558230503, 0.016471337298813494, 0.012237410822825125, -0.005186559094895448, -0.01690838648792824, -0.02720638699385919, 0.0153104213738989, -0.011691097939447849, 0.030784736892207756, 0.01714056892785311, 0.001748201529487115, -0.014723134954419138, -0.0013452956732225858, -0.01924387525180236, 0.032013941112637265, -0.0009662911045588348, -0.009464872869836258, 0.009464872869836258, -0.01604794316109856, 0.010475551564385835, -0.020923787438036676, -0.01660791388984333, 0.00487925803978807, -0.019462400777682295, -0.036903440440975196, 0.016198180391463576, 0.010516525100488321, -0.013077366915942282, 0.0017652738361964848, -0.014941660480299074, -0.01572015673492378, -0.005135341941936698, -0.018137590708357753, -0.017686882742552947, -0.009901922990273567, -0.012189608829700169, -0.0024806023231658822, 0.01690838648792824, 0.00218183753782851, 0.010086303437073481, -0.005947982809980144, -0.001200181299023582, 0.03422651019952648, -0.011540861640405393, 0.027547832196724027, -0.02461140009932521, 0.010639445708795785, -0.02151107385751644, -0.007819104831359402, 0.00555873468266779, 0.0070337796540509475, 0.011663782248712857, -0.018301484852767703, -0.007887394058196882, 0.0004793042832698092, -0.005084125254639228, 0.0034025054884880153, -0.011670610705735324, 0.00829029909955417, 0.001421267379871622, 0.004981691414383009, 0.01182084700477778, -0.011814018547755312, -0.01514652722948895, 0.017509331684098062, -0.008836612914254006, 0.006777695286241039, 0.0029142382150919573, -0.0054358140743603275, 0.007054266422102192, -0.01903900663996736, 0.020664289307376814, 0.01570649795823372, -0.008269812797164206, -0.014231453452511846, -0.014723134954419138, 0.014176822071041862, -0.00010632829651525048, -0.03643907556112545, -0.022685646696475967, -0.03551034207613573, -0.016990333560133217, 0.021210601259431527, -0.015460657672941356, -0.007716670991103182, 0.005726043055588975, 0.008583942309294051, -0.0053299660055928745, 0.007450343472098293, -0.016635229580578323, -0.024010454903155388, -0.007907880360586844, 0.007866906824484357, -0.02799854016252883, -0.007969340199079295, -0.022917829136400836, 0.023218301734485747, 0.0095536483990637, -0.03725854628317521, -0.011602322410220406, 0.008631745233741567, -0.02676933594209932, 0.001412731226516937, -0.0020879399673422953, 0.009840462220458554, 0.002565963856712732, -0.016717176652783296, 0.015829419497863748, 0.006111876488728814, -0.0065352692294599075, 0.014654845727581658, -0.02107402280575657, -0.009792660227333598, 0.012169121595987644, 0.005039737490025507, 0.02433824319197529, -0.012606171716424953, -0.012182779441355141, -0.024515794250430174, 0.007586921460111971, 0.01675815112020835, 0.005104612022690472, 0.015255789992428917, -0.0036534680478697928, -0.0061528500248313025, 0.0029995997486388067, 0.007935196051321836, 0.018233196557252786, -7.933275518680437e-05, 0.013999270081264415, 0.0032386115769087046, -0.01265397464087247, 0.01238081773352255, -0.01068724770192074, 0.0022211037268447405, -0.005043151718536741, -0.008133234343489247, -0.007846420522094394, 0.003533962133734844, -0.012175950984332674, 0.002161350769777266, -0.0029756985192456887, -0.04793896459675092, -0.019667267526872173, 0.013930980854426936, 0.0015757714645531192, 0.021620336620456405, -0.017604935670347974, -0.015692841044188787, -0.011609150867242873, 0.016184521614773517, -0.017768829814757924, -0.01973555582238709, 0.026742020251364327, 0.014368031906186806, 0.026113761227104636, -0.0034110417582580207, -0.0057704308202026966, -0.03504597719628599, -0.010461893719018338, -0.00456171336782443, -0.007976169587424324, -0.0020333085858723118, 0.006204066712128771, 0.007969340199079295, -0.025526474807624874, 0.0019735556288048373, -0.006091389720677571, -0.022453464256551096, 0.005401669460941587, -0.0074161988586795525, -0.005773845514375211, -0.0013999270546925695, -0.007095239958204679, 0.0157884450304387, 0.0022228108411003573, -0.001106283844952688, -0.004807554118778076, 0.006186994638250042, 0.012442278503337564, -0.0009321465493477551, 0.21950855547027248, -0.008652231536131531, 0.008802467835173987, 0.03100326241808769, 0.011431598877465426, -0.026660073179159353, 0.030074528933097967, 0.007907880360586844, 0.01055749863659081, 0.017400068921158095, -0.0018147834092383374, -0.004800725196094328, -0.0028681431033919787, 0.009901922990273567, 0.0036500535865279186, 0.009178058117118843, -0.020104318578632045, -0.007552776846693231, -0.02414703335683035, -0.022357858407656063, 0.024119717666095355, 0.012858841390062346, -0.019954081348267025, 0.008420049096206661, 0.038733589857574524, 0.021825203369646284, -0.029255060073693332, -0.0052719203956116565, 0.008904901209768924, 0.0030405732847412943, -0.013309550287189713, -0.011288191966768, -0.006381618701906218, -0.007948853896689333, 0.0005160096844872944, -0.01061895847508326, -0.015487973363676348, 0.021524730771561373, 0.004906573264861781, 0.013603193496929594, -0.03225978046660707, 0.0063201583977524865, -0.01038677603515839, -0.007368396399893317, -0.01311834045204477, 0.031959309731167285, -0.016594256975798395, -3.185047491094442e-05, 0.014531925119274196, 0.00995655437174355, -0.008631745233741567, 0.020363816709291903, 0.023382195878895697, 0.016703519738738362, -0.012169121595987644, 0.007518632233274492, 0.03163152144234738, 0.003487867022034865, -0.00307130320398752, 0.015843076411908682, -0.000883490533433711, 0.023764615549185585, -0.020104318578632045, 0.021456442476046455, -0.014941660480299074, 0.009567306244431197, -0.007750815604521922, 0.006927931585283494, 0.009369267952263786, -0.006917687968427232, 0.00241402044341466, -0.015050922311916478, -0.0009918995064152295, 0.008413219707861633, -0.01332320813255721, -0.030183791696037934, 0.02227591133545109, 0.01974921459907715, 0.020254553946351936, 0.014832397717359105, -0.0037729739620047417, 0.004855356577564311, -0.012660803097894937, -0.006869885975302277, -0.010147763275565932, -0.034335769237176204, 0.015173842920223942, 0.01741372583520303, 0.005172901249527952, 0.013958296545161928, -0.024078745061315427, -0.011458914568200418, 0.017768829814757924, -0.018697561437102522, 0.03217783525704722, 0.024256296119770315, -0.01690838648792824, 0.027261018375329172, -0.008652231536131531, -0.0019974568581979553, -0.0022415904948959843, -0.0011694512633620363, 0.03693075799435531, 0.005186559094895448, -0.008078602962019264, 0.011691097939447849, -0.009526332708328708, -0.0006427713580775557, 0.0006171629562211609, 0.007559605769376979, -0.018506351601957582, -0.010038501443948526, -0.006190408866761275, -0.009738028845863615, 0.016444021608078504, 0.01311834045204477, -0.010209224045380943, -0.0016397925565055963, 0.0038412631888422215, 0.0021733012680585045, 0.003622737895792927, -0.025116739446599996, 0.01055749863659081, 0.008433706941574158, -0.008440535398596625, -0.018875114358202532, -0.019011690949232368, 0.011438428265810456, -0.023709984167715602, -0.04029058236682394, -0.00695866150452972, -0.005087539483150462, -0.00729327825037209, -0.0009867778144024186, -0.013043222768184823, 0.012811039396937392, 0.0046641472080806495, -0.036411761733035584, -0.014204137761776854, 0.016198180391463576, 0.007402541013312057, -0.014231453452511846, 0.015993311779628577, 0.01729080615821813, -0.008652231536131531, -0.01608891762852361, 0.014504609428539202, 0.01771419843328794, -0.018670245746367532, -0.0337621415943865, -0.03630249897009562, 0.010769194774125716, -0.005500689072686573, -0.01608891762852361, 0.019503373382462223, -0.015556262590513828, -0.02151107385751644, -0.014067559308101895, 0.013097854149654807, -0.008877585519033932, -0.04080957862814366, -0.00574652982364022, 0.019639951836137183, -0.008966361979583937, -0.008344930481024153, -0.0026564469658570725, -0.17820729068360872, 0.0014067559773763177, 0.013999270081264415, -0.02011797549267698, -0.0020862326202560383, 0.01574747242565877, 0.02709712423091922, -0.009813146529723562, -0.007108897803572175, 0.0008480655261155984, 0.03482745167040606, -0.005531418991932799, -0.04660049761338145, -0.008222010804039252, 0.012688118788629929, -0.026250339680779597, 0.004851942349053078, -0.015187500765591439, 0.007020121808683452, 0.010837484000963196, 0.044797665750162224, -0.03086668396441273, 0.016334758845138537, -0.025949867082694686, 0.005504103301197807, 0.01771419843328794, -0.0032249537315412087, -0.010810168310228203, -0.0051148551738854535, -0.021128654187226554, -0.025758657247549745, 9.507126246865347e-05, 0.020199922564881952, 0.008167379422569268, 0.011882307774592793, 0.013091024761309779, 0.007996655889814288, -0.006736721750138551, -0.0053197228543978925, 0.012824697242304887, 0.014531925119274196, 0.04083689618152377, 0.02231688580287614, 0.0010857970769014439, -0.014490951583171707, 0.02227591133545109, 0.017796145505492914, 0.010851141846330691, 0.027493200815254044, -0.026113761227104636, 0.004633416823173143, -0.00846102263230915, 0.015692841044188787, 0.010653103554163282, 0.0344177181720263, 0.02450213733638524, 0.0036500535865279186, -0.009096111044913868, -0.0027691239573082735, -0.007484488085517033, -0.021756915074131366, -0.027397596829004132, -0.005627023909505271, -0.014723134954419138, -0.002270613299886593, -0.016198180391463576, -0.01195059607010771, 0.010612130018060793, -0.03750438563714501, 0.0003608653446484507, -0.01924387525180236, 0.014163164225674367, 0.032314411848077054, -0.023696325391025543, 0.010311657419975882, 0.00905513750881138, -0.02123791695016652, 0.013357352280314668, -0.015870392102643672, -0.011411112575075462, -0.0123193578950301, 0.047037548665141315, -0.015597235195293754, -0.02920042869222335, 0.001729421992106808, 0.03239636078292715, 0.010140934818543465, -0.0008826369180982424, 0.00507729633195548, 0.0011370138806142335, 0.02846290690502369, -0.01951703215915228, -0.014053901462734398, -0.03083936827367774, 0.024024113679845444, 0.01841074761570767, 0.0132480895173747, 0.01660791388984333, -0.0010166542929361559, -0.014449978047069219, -0.0017908822962605397, -0.01038677603515839, -0.0030149647082619194, 0.003206174310576222, 0.025389896353949917, 0.003527133211051096, 0.025867920010489712, 0.0169220452646183, 0.027383938052314077, -0.006682090834329848, -0.0063918618531012, 0.004602686903926918, 0.020527710853701857, 0.013009077689104802, 0.007812275443014373, -0.008631745233741567, -0.010482380021408302, -0.00024007894930263884, 0.0008869049947755849, -0.020391132400026896, 0.042366571137393075, 0.01507823800265147, -0.0024464577097471425, 0.011213074282908053, -0.023614378318820566, -0.011015035059418081, -0.10767828523927685, -0.03720391490170523, -0.010038501443948526, 0.03892480155536459, 0.008734178608336507, -0.002461822902200896, -0.002948382828510697, 0.018342459320192753, -0.018984375258497378, 0.02999258186089299, -0.006350888316998713, -0.021552046462296366, 0.0019428255931432917, -0.003117398548518139, 0.011096982131623056, 0.008413219707861633, 0.006600143762124873, -0.01831514362945776, -0.014286084833981829, -0.003475916290922986, 0.0010456772143420847, 0.001141282015499236, 0.001321394560244788, -0.004414891762954489, -0.006064074029942579, 0.004408062840270741, -0.048157490122630854, 0.03070278982000278, 0.03471818890746609, -0.0035373765950767176, 0.014600214346111674, -0.030921315345882713, 0.00865906092447656, -0.02517137082806998, -0.00878880998980649, 0.020623314839951765, -0.004483180989791969, 0.0018164906399092745, 0.03217783525704722, -0.015132869384121455, 0.012831526630649917, 0.0074161988586795525, -0.007648381764265703, -0.014463635892436716, 0.008836612914254006, -0.0056645827514352435, 0.0015919902141346806, 0.02691957130981921, 0.004080275017112119, -0.022590042710226056, -0.032669517690277074, -0.006740136444311065, -0.016403047140653455, 0.005900180351193908, 0.043349936003852785, -0.022549068242801007, 0.0047358506634293624, 0.032478305992487, 0.0054358140743603275, 0.025949867082694686, -0.004964619340504279, -0.021852519060381277, 0.020213579478926887, 0.03608397344421568, 0.01903900663996736, 0.013241261060352233, -0.01729080615821813, -0.017987355340637858, -0.0019172171330792368, -0.02044576378149688, 0.004394404994903245, 0.019762871513122084, -0.029883320960598148, 0.03889748400198448, -0.018028327945417786, 0.020636973616641824, -0.01994042443422209, 0.007798617597646877, 0.012073516678415174, -0.03042963291265286, -0.010038501443948526, -0.015692841044188787, 0.01882048297673255, -0.01421779560714435, 0.022508095638021083, 0.001483581241153162, -0.001630402846023103, 0.01688107079719325, 0.0050090071051180005, -0.01662157266653339, 0.010933088918535666, -0.006801596748464797, 0.02004968719716206, -0.03458161231643626, 0.011902794076982755, 0.009307807182448774, 0.007914709748931874, -0.0017268612043080625, 0.0045685422905081775, 0.01827416916203271, 0.009000506127341396, -0.006238211325547511, -0.09139816336354367, 0.014504609428539202, -0.016444021608078504, 0.007054266422102192, 0.014764108490521627, -0.0033632392994717847, 0.00015215670071661898, -0.02681031040952437, -0.016498652989548487, -0.0028835082958457315, -0.023587062628085576, 0.011131127210703078, -0.006087975492166337, 0.008351759869369181, -0.0030405732847412943, -0.015856735188598738, 0.0054870312273190775, 0.0030695960897319033, 0.0014554118768750415, 0.012626658950137478, -0.0013137119640179117, -0.0023576819476890595, 0.023122697748235835, -0.013801231789097005, -0.017427384611893085, 0.0027622950346245256, -0.012373989276500083, 0.005463129765095319, -0.017891749491742825, -0.00811957649812175, 0.019134612488862394, -0.021524730771561373, 0.024324586277930355, 0.035346451657016026, -0.004373918226852001, -0.021961781823321244, -0.017919065182477815, 0.0024567010937727647, -0.005756772974835201, 0.01558357828124882, -0.0028647286420501045, -0.02054136776774679, 0.012524225575542539, -0.01924387525180236, 0.010161421120933427, -0.0007234379199678384, -0.009635595471268677, 0.007265962559637098, 0.027820989104073945, 0.016170864700728583, 0.02074623637958179, 0.012763237403812437, -0.013200287524249746, 0.002395241022449673, -0.02917311300148836, -0.03411724743658651, 0.012032543142312686, -0.0037354151200747684, -0.00429538584881954, -0.027643436182973935, -0.0021459855773235128, 0.03925258611889425, 0.009232689498588827, -0.0032505623080205837, 0.0039505259517821885, 0.011335993959892954, -0.0006679529813700463, -0.031658838995727495, 0.003527133211051096, -0.03742244042758516, -0.01541968413683887, -0.012578856025689962, 0.014012927926631912, 0.0019138026717373626, 0.009362438563918758, 0.010161421120933427, -0.015556262590513828, -0.014340716215451814, -0.012735921713077445, 0.032013941112637265, -0.017099596323073184, -0.009130256123993888, -0.008037629425916775, 0.010018014210236001, 0.022289570112141145, 0.0005177169151582314, -0.010502867255120826, 0.006255283865087522, 0.007170358107725907, 0.006746965366994814, -0.0006056391782961663, 0.01827416916203271, 0.0044490363763732286, -0.02384656262139056, 0.005108026251201705, 0.004244169161522071, -0.014204137761776854, 0.003967598025660918, 0.00010366075586786894, 0.03747707180905514, 0.007013292885999703, -0.006528440306776159, -0.0284355912142887, 0.01265397464087247, -0.009683397464393631, 0.012469594194072555, -0.027383938052314077, -0.016935702178663234, -0.021388154180531537, 0.02381924693065557, 0.01921655956106737, -0.007586921460111971, 0.005432399845849094, 0.013760258252994517, -0.004455865299056977, 0.020377473623336837, -0.006169922098710032, -0.018588298674162555, -0.01711325509976324, 0.014859713408094097, 0.012961275695979848, 0.010468722176040805, 0.017154227704543168, -0.008877585519033932, 0.012141805905252653, 0.005541662143127781, 0.038733589857574524, -0.026414231962544426, -0.009280491491713783, 0.008181037267936763, -0.016894729573883306, -0.02584060431975472, -0.01824685347129772, -0.013159313988147257, -0.017727857209977996, -0.00906196689715641, 0.013091024761309779, 0.014600214346111674, -0.02447482164565025, 0.03504597719628599, 0.004650489362713154, 0.018533667292692572, 0.0053299660055928745, -0.0284355912142887, -0.006128948562607543, 0.035674236220545684, 0.01790540826843288, -0.017236174776748145, 0.014327058370084318, 0.018724877127837516, -0.01281786878528242, -0.011438428265810456, -0.012394475578890047, -0.021838862146336343, -0.006699162908208578, -0.013268576751087224, 0.0038856511862865833, -0.005022664950485496, 0.0042612412354008, 0.02492552961145505, 0.008331272635656656, 0.018806824200042493, -0.0016986919564452624, -0.02642789073923448, -0.012442278503337564, 0.03512792613113609, -0.0014878492596228443, -0.014463635892436716, -0.00855662754988162, 0.009150742426383852, 0.012578856025689962, -0.02920042869222335, -0.0029927708259550588, 0.024283611810505305, -0.01581576072117369, 0.004315872616870784, -0.016553282508373346, -0.0033990910271461416, 0.0009543404898622759, -0.01718154339527816, 0.007061095344785939, -0.002262077262947228, -0.018533667292692572, 0.008228839261061719, 0.019954081348267025, -0.017509331684098062, -0.014641187882214163, -0.011260876276033008]\n"
     ]
    }
   ],
   "source": [
    "text1 = \"Cat\"\n",
    "text2 = \"Kpop\"\n",
    "text3 = \"Kitten\"\n",
    "\n",
    "embed1 = embeddings.embed_query(text1)\n",
    "embed2 = embeddings.embed_query(text2)\n",
    "embed3 = embeddings.embed_query(text3)\n",
    "\n",
    "print(f\"Embed1 == {embed1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity1 %: 88.31033101464733\n",
      "Similarity2 %: 75.74192695239827\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "similarity1 = np.dot(embed1, embed3)\n",
    "similarity2 = np.dot(embed1, embed2)\n",
    "print(f\"Similarity1 %: {similarity1*100}\")\n",
    "print(f\"Similarity2 %: {similarity2*100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "persist_directory = \"./data/db/chroma\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma.from_documents(\n",
    "    documents = splits,\n",
    "    embedding = embeddings,\n",
    "    persist_directory=persist_directory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96\n"
     ]
    }
   ],
   "source": [
    "print(vectorstore._collection.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"what do they say about ReAct prompting method?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_resp = vectorstore.similarity_search(query=query, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "Published as a conference paper at ICLR 2023\n",
      "appear sparsely in the most relevant positions of a trajectory, so we let the language model decide the\n",
      "asynchronous occurrence of thoughts and actions for itself.\n",
      "Since decision making and reasoning capabilities are integrated into a large language model, ReAct\n",
      "enjoys several unique features: A) Intuitive and easy to design : Designing ReAct prompts is\n",
      "straightforward as human annotators just type down their thoughts in language on top of their actions\n",
      "taken. No ad-hoc format choice, thought design, or example selection is used in this paper. We detail\n",
      "prompt design for each task in Sections 3 and 4. B) General and ﬂexible : Due to the ﬂexible thought\n",
      "space and thought-action occurrence format, ReAct works for diverse tasks with distinct action\n",
      "spaces and reasoning needs, including but not limited to QA, fact veriﬁcation, text game, and web\n",
      "navigation. C) Performant and robust :ReAct shows strong generalization to new task instances\n",
      "while learning solely from one to six in-context examples, consistently outperforming baselines with\n",
      "only reasoning or acting across different domains. We also show in Section 3 additional beneﬁts\n",
      "when ﬁnetuning is enabled, and in Section 4 how ReAct performance is robust to prompt selections.\n",
      "D) Human aligned and controllable :ReAct promises an interpretable sequential decision making\n",
      "and reasoning process where humans can easily inspect reasoning and factual correctness. Moreover,\n"
     ]
    }
   ],
   "source": [
    "print(len(docs_resp))\n",
    "print(docs_resp[0].page_content)\n",
    "vectorstore.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrievers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = Chroma(persist_directory=persist_directory,\n",
    "                      embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Published as a conference paper at ICLR 2023\n",
      "appear sparsely in the most relevant positions of a trajectory, so we let the language model decide the\n",
      "asynchronous occurrence of thoughts and actions for itself.\n",
      "Since decision making and reasoning capabilities are integrated into a large language model, ReAct\n",
      "enjoys several unique features: A) Intuitive and easy to design : Designing ReAct prompts is\n",
      "straightforward as human annotators just type down their thoughts in language on top of their actions\n",
      "taken. No ad-hoc format choice, thought design, or example selection is used in this paper. We detail\n",
      "prompt design for each task in Sections 3 and 4. B) General and ﬂexible : Due to the ﬂexible thought\n",
      "space and thought-action occurrence format, ReAct works for diverse tasks with distinct action\n",
      "spaces and reasoning needs, including but not limited to QA, fact veriﬁcation, text game, and web\n",
      "navigation. C) Performant and robust :ReAct shows strong generalization to new task instances\n",
      "while learning solely from one to six in-context examples, consistently outperforming baselines with\n",
      "only reasoning or acting across different domains. We also show in Section 3 additional beneﬁts\n",
      "when ﬁnetuning is enabled, and in Section 4 how ReAct performance is robust to prompt selections.\n",
      "D) Human aligned and controllable :ReAct promises an interpretable sequential decision making\n",
      "and reasoning process where humans can easily inspect reasoning and factual correctness. Moreover,\n"
     ]
    }
   ],
   "source": [
    "retriever = vector_store.as_retriever(search_kwargs={\"k\":2})\n",
    "docs = retriever.get_relevant_documents(\"Tell me more about ReAct Prompting\")\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm = llm,\n",
    "    chain_type = \"stuff\",\n",
    "    retriever = retriever,\n",
    "    verbose = True,\n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_llm_response(llm_response):\n",
    "    print(llm_response['result'])\n",
    "    print('\\n\\nSources:')\n",
    "    for source in llm_response[\"source_documents\"]:\n",
    "        print(source.metadata['source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " ReAct prompting is a novel paradigm that combines reasoning and acting in language models for general task solving. It allows human annotators to type down their thoughts in language on top of their actions taken, making it easy and intuitive to design. It is also flexible and general, working for diverse tasks with distinct action spaces and reasoning needs. ReAct is performant and robust, consistently outperforming baselines with only reasoning or acting across different domains. Additionally, ReAct promises an interpretable sequential decision making and reasoning process, where humans can easily inspect reasoning and factual correctness. It is limited in its support of reasoning and acting behaviors, but can potentially improve with additional training data and by combining with other paradigms like reinforcement learning.\n",
      "\n",
      "\n",
      "Sources:\n",
      "./data/react-paper.pdf\n",
      "./data/react-paper.pdf\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "query = \"tell me more about ReAct prompting\"\n",
    "llm_response = qa_chain(query)\n",
    "print(process_llm_response(llm_response=llm_response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Agents + Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import Tool, initialize_agent, load_tools\n",
    "from langchain.chains import LLMMathChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculator useful for when you need to answer questions related to Math.\n"
     ]
    }
   ],
   "source": [
    "llm_math = LLMMathChain.from_llm(llm=llm)\n",
    "math_tool = Tool(\n",
    "    name=\"Calculator\",\n",
    "    func = llm_math.run,\n",
    "    description = \"useful for when you need to answer questions related to Math.\"\n",
    ")\n",
    "\n",
    "tools = [math_tool]\n",
    "print(tools[0].name, tools[0].description)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = initialize_agent(\n",
    "    agent = \"zero-shot-react-description\",\n",
    "    tools =tools,\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    max_iteration=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should use a calculator to solve this problem\n",
      "Action: Calculator\n",
      "Action Input: 3.1^2.1\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAnswer: 10.761171606099687\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: 10.761171606099687\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'what is 3.1^2.1', 'output': '10.761171606099687'}\n"
     ]
    }
   ],
   "source": [
    "print(agent(\"what is 3.1^2.1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = load_tools(\n",
    "    ['llm-math'],\n",
    "    llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculator Useful for when you need to answer questions about math.\n"
     ]
    }
   ],
   "source": [
    "print(tools[0].name, tools[0].description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m We need to use the calculator to solve this problem.\n",
      "Action: Calculator\n",
      "Action Input: 45 + 50\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAnswer: 95\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m Now we need to add the number of kids he has.\n",
      "Action: Calculator\n",
      "Action Input: 4 + 7\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAnswer: 11\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: James will be 95 years old in 50 years and he will have 11 children.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "James will be 95 years old in 50 years and he will have 11 children.\n"
     ]
    }
   ],
   "source": [
    "query = \"If James is currently 45 years old, how old will he be in 50 years? \\\n",
    "    If he has 4 kids and adopted 7 more, how many children does he have?\"\n",
    "result = agent(query)\n",
    "print(result['output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"query\"],\n",
    "    template=\"{query}\"\n",
    ")\n",
    "\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_tool = Tool(\n",
    "    name=\"Language Model\",\n",
    "    func = llm_chain.run,\n",
    "    description = \"Use this tool for general queries and logic\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = load_tools(\n",
    "    ['llm-math'],\n",
    "    llm=llm\n",
    ")\n",
    "\n",
    "tools.append(llm_tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = initialize_agent(\n",
    "    agent=\"zero-shot-react-description\",\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    max_iterations=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "Calculator(*args: Any, callbacks: Union[List[langchain_core.callbacks.base.BaseCallbackHandler], langchain_core.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> Any - Useful for when you need to answer questions about math.\n",
      "Language Model(*args: Any, callbacks: Union[List[langchain_core.callbacks.base.BaseCallbackHandler], langchain_core.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> Any - Use this tool for general queries and logic\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [Calculator, Language Model]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin!\n",
      "\n",
      "Question: {input}\n",
      "Thought:{agent_scratchpad}\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to add up all the eggs we have\n",
      "Action: Calculator\n",
      "Action Input: 54 + 10 + (5 * 12)\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAnswer: 124\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: 124 eggs\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "124 eggs\n"
     ]
    }
   ],
   "source": [
    "query = \"if I have 54 eggs and Mary has 10, and 5 more people have 12 eggs each.  \\\n",
    "    How many eggs to we have in total?\"\n",
    "    \n",
    "print(agent.agent.llm_chain.prompt.template)\n",
    "\n",
    "result = agent(query)\n",
    "print(result['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "Calculator(*args: Any, callbacks: Union[List[langchain_core.callbacks.base.BaseCallbackHandler], langchain_core.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> Any - Useful for when you need to answer questions about math.\n",
      "Language Model(*args: Any, callbacks: Union[List[langchain_core.callbacks.base.BaseCallbackHandler], langchain_core.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> Any - Use this tool for general queries and logic\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [Calculator, Language Model]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin!\n",
      "\n",
      "Question: {input}\n",
      "Thought:{agent_scratchpad}\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should use a language model to answer this question.\n",
      "Action: Language Model\n",
      "Action Input: \"What's the capital of China?\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m\n",
      "\n",
      "Beijing\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: Beijing\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Beijing\n"
     ]
    }
   ],
   "source": [
    "query = \"What's the capital of China?\"\n",
    "    \n",
    "print(agent.agent.llm_chain.prompt.template)\n",
    "\n",
    "result = agent(query)\n",
    "print(result['output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversational Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(memory_key = \"chat_history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversational_agent = initialize_agent(\n",
    "    agent = \"conversational-react-description\",\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    max_iterations=3,\n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant is a large language model trained by OpenAI.\n",
      "\n",
      "Assistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
      "\n",
      "Assistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
      "\n",
      "Overall, Assistant is a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.\n",
      "\n",
      "TOOLS:\n",
      "------\n",
      "\n",
      "Assistant has access to the following tools:\n",
      "\n",
      "> Calculator: Useful for when you need to answer questions about math.\n",
      "> Language Model: Use this tool for general queries and logic\n",
      "\n",
      "To use a tool, please use the following format:\n",
      "\n",
      "```\n",
      "Thought: Do I need to use a tool? Yes\n",
      "Action: the action to take, should be one of [Calculator, Language Model]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "```\n",
      "\n",
      "When you have a response to say to the Human, or if you do not need to use a tool, you MUST use the format:\n",
      "\n",
      "```\n",
      "Thought: Do I need to use a tool? No\n",
      "AI: [your response here]\n",
      "```\n",
      "\n",
      "Begin!\n",
      "\n",
      "Previous conversation history:\n",
      "{chat_history}\n",
      "\n",
      "New input: {input}\n",
      "{agent_scratchpad}\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
      "Action: Calculator\n",
      "Action Input: 2023 - 1917\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAnswer: 106\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m Do I need to use a tool? No\n",
      "AI: A person born in 1917 would be 106 years old in 2023.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
      "Action: Calculator\n",
      "Action Input: 106 * 100\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAnswer: 10600\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m Do I need to use a tool? No\n",
      "AI: That person would be 10600 years old. However, it is not possible for a person to live that long.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "query = \"How old is a person born in 1917 in 2023\"\n",
    "    \n",
    "query_two = \"How old would that person be if their age is multiplied by 100?\"\n",
    "    \n",
    "print(conversational_agent.agent.llm_chain.prompt.template)\n",
    "\n",
    "result = conversational_agent(query)\n",
    "results = conversational_agent(query_two)\n",
    "# print(result['output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Docstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import Wikipedia\n",
    "from langchain.agents.react.base import DocstoreExplorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "docstore = DocstoreExplorer(Wikipedia())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Search\",\n",
    "        func=docstore.search,\n",
    "        description=\"search wikipedia\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Lookup\",\n",
    "        func=docstore.lookup,\n",
    "        description=\"lookup a term in wikipedia\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "docstore_agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=\"react-docstore\",\n",
    "    verbose=True,\n",
    "    max_iterations=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to search Seventeen and find their latest single.\n",
      "Action: Search[Seventeen]\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/wikipedia/wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Observation: \u001b[36;1m\u001b[1;3mCould not find [Seventeen]. Similar: ['17', 'At Seventeen', 'Seventeen Seconds', 'Seventeen (South Korean band)', 'Going Seventeen', 'Seventeen discography', 'Edge of Seventeen', 'The Edge of Seventeen', 'Going Seventeen (web series)', 'List of Seventeen live performances']\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m Seventeen is a South Korean band, so I need to search Seventeen (South Korean band) and find their latest single.\n",
      "Action: Search[Seventeen (South Korean band)]\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mSeventeen (Korean: 세븐틴; RR: Sebeuntin; stylized in all caps or as SVT) is a South Korean boy band formed by Pledis Entertainment. The group consists of thirteen members: S.Coups, Jeonghan, Joshua, Jun, Hoshi, Wonwoo, Woozi, DK, Mingyu, The8, Seungkwan, Vernon, and Dino. Seventeen has won a large audience since its debut and has grown into an internationally recognized K-pop group with signature music and performances.\n",
      "The group debuted on May 26, 2015, with the extended play (EP) 17 Carat, which became the longest-charting K-pop album of the year in the US and the only rookie album to appear on Billboard's \"10 Best K-Pop Albums of 2015\" list. Seventeen has released four studio albums, twelve EPs, and three reissues.\n",
      "Seventeen is considered a \"self-producing\" idol group, with the members involved in songwriting, music production, and choreographing, among other aspects of their music and performances. They perform as one group and are divided into three units—hip-hop, vocal, and performance—each with a different area of specialization. They have been labeled \"Performance Kings\", \"Theater Kids of K-Pop\", and \"K-Pop Performance Powerhouse'\" by various domestic and international media outlets.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m Seventeen has released four studio albums, twelve EPs, and three reissues, so I need to find their latest EP.\n",
      "Action: Search[Seventeen (South Korean band) discography]\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mSeventeen (Korean: 세븐틴; RR: Sebeuntin; stylized in all caps or as SVT) is a South Korean boy band formed by Pledis Entertainment. The group consists of thirteen members: S.Coups, Jeonghan, Joshua, Jun, Hoshi, Wonwoo, Woozi, DK, Mingyu, The8, Seungkwan, Vernon, and Dino. Seventeen has won a large audience since its debut and has grown into an internationally recognized K-pop group with signature music and performances.\n",
      "The group debuted on May 26, 2015, with the extended play (EP) 17 Carat, which became the longest-charting K-pop album of the year in the US and the only rookie album to appear on Billboard's \"10 Best K-Pop Albums of 2015\" list. Seventeen has released four studio albums, twelve EPs, and three reissues.\n",
      "Seventeen is considered a \"self-producing\" idol group, with the members involved in songwriting, music production, and choreographing, among other aspects of their music and performances. They perform as one group and are divided into three units—hip-hop, vocal, and performance—each with a different area of specialization. They have been labeled \"Performance Kings\", \"Theater Kids of K-Pop\", and \"K-Pop Performance Powerhouse'\" by various domestic and international media outlets.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m Seventeen's latest EP is \"Your Choice\", released on June 18, 2021. So the answer is \"Your Choice\".\n",
      "Action: Finish[\"Your Choice\"]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "query = \"What was Seventeen's latest single?\"\n",
    "result = docstore_agent.run(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More agent work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "prompt = ChatPromptTemplate.from_template(template=\"Create a social media post about {topic}\")\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | model | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Just discovered the fascinating world of generative AI! This technology is truly revolutionary, allowing machines to create art, music, and even write stories. The possibilities are endless and I can't wait to see how this technology continues to evolve. #GenerativeAI #ArtificialIntelligence #Innovation\""
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"topic\": \"generative AI\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.agents import create_openai_functions_agent\n",
    "from langchain.agents import AgentExecutor\n",
    "from langchain.tools import DuckDuckGoSearchRun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_math_chain = LLMMathChain.from_llm(llm=model, verbose=True)\n",
    "math_tool = Tool.from_function(\n",
    "    func = llm_math_chain.run,\n",
    "    name=\"Calculator\",\n",
    "    description=\"useful for when you need to enter questions about math. Only for math questions and nothing else.\"\n",
    ")\n",
    "\n",
    "search_tool = DuckDuckGoSearchRun()\n",
    "\n",
    "tools = [math_tool, search_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThe tallest building in the world is the Burj Khalifa in Dubai, United Arab Emirates, which stands at a height of 828 meters (2,717 feet).\n",
      "\n",
      "The average distance from the Earth to the moon is about 384,400 kilometers (238,855 miles). To calculate how many times you would need to stack the Burj Khalifa to reach the moon, we can use the following calculation:\n",
      "\n",
      "1 kilometer = 1000 meters\n",
      "384,400 kilometers * 1000 = 384,400,000 meters\n",
      "\n",
      "384,400,000 meters / 828 meters (height of the Burj Khalifa) = approximately 464,251.21\n",
      "\n",
      "Therefore, you would need to stack the Burj Khalifa approximately 464,251 times to reach the moon.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'what is the tallest building in the world and how many times would you need to stack this building to reach the moon?', 'output': 'The tallest building in the world is the Burj Khalifa in Dubai, United Arab Emirates, which stands at a height of 828 meters (2,717 feet).\\n\\nThe average distance from the Earth to the moon is about 384,400 kilometers (238,855 miles). To calculate how many times you would need to stack the Burj Khalifa to reach the moon, we can use the following calculation:\\n\\n1 kilometer = 1000 meters\\n384,400 kilometers * 1000 = 384,400,000 meters\\n\\n384,400,000 meters / 828 meters (height of the Burj Khalifa) = approximately 464,251.21\\n\\nTherefore, you would need to stack the Burj Khalifa approximately 464,251 times to reach the moon.'}\n"
     ]
    }
   ],
   "source": [
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "agent = create_openai_functions_agent(llm=model, tools=tools, prompt=prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "result = agent_executor.invoke({\"input\": \"what is the tallest building in the world and how many times would you need to stack this building to reach the moon?\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Chain Types  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.chains.mapreduce import MapReduceChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.text_splitter import CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OpenAI(model_name=\"gpt-3.5-turbo-instruct\", temperature=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stuff Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"./data/Software-Engineer-CV.pdf\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document No 1\n",
      "Name: Sunil Sharma                              Mobile: +91 9898989898  \n",
      " \n",
      "Designation: Senior Technical Lead                      Mail Id: sunil.sharma @gmail.com  \n",
      " \n",
      "Objective:   \n",
      "Experienced S enior Software Developer with 1 2 years of hands -on expertise in \n",
      "designing, developing, and delivering high -quality software solutions.  \n",
      "Proven track record of successfully leading and collaborating with cross -functional \n",
      "teams to deliver projects on time and within budget. Seeking to leverage my technical \n",
      "skills and leadership experience to contribute to innovative software projects.  \n",
      "Education:  \n",
      "Bachelor in Engineering in Electronics and Communication  \n",
      "K.L.N.  College of Information Technology, Madurai - 2007  \n",
      "Professional Summary:  \n",
      "• 12 years  of experience in Software Development in C on  Linux Environment . \n",
      "• Over 5 years of programming  experience as an Oracle PL/SQL  developer in \n",
      "Analysis, Design and Implementation of business application using Oracle DBMS . \n",
      "• Expertise in all stages of Software Development Life Cycle. \n",
      "• Effectively made use of Table functions, indexes, Table partitioning , Collections , \n",
      "Analytical functions  and materialized views . \n",
      "• Created tables, views, constraints  and indexes  (B Tree and function based).  \n",
      "• Developed complex DB objects like packages , procedures , functions  and triggers  \n",
      "using PL/SQL  \n",
      "• Experience in Oracle -supplied  packages, Dynamic SQL , records  and tables . \n",
      "• Loaded data into database tables using SQL Loader . \n",
      "• Good knowledge of Oracle performance -related features like query optimizer , \n",
      "execute plans  and indexes . \n",
      " \n",
      "Experience :\n",
      "Document No 2\n",
      "• Working as a Senior Technical Lead  in HCL-EHI project  since  August -2019 to till \n",
      "date  \n",
      " \n",
      "• Worked  as a Technical Lead  in NOKIA NETWORKS  in Research and Design \n",
      "Division of Protocol development and Digital Home  BU since August -2013  to \n",
      "September -2018  \n",
      " \n",
      "• Worked as a Senior Engineer  in Plintron  Global Technology Solutions Pvt. Ltd.  \n",
      " in Research and Design Division from June -2011 to August -2013  \n",
      " \n",
      "Skills:  \n",
      "• Programming  Languages:  PL/SQL, C, Pro C, Shell scripting  \n",
      "• Database Management: Oracle  \n",
      "• Operating System: Linux  \n",
      "• Version Control: GIT, TFS, CVS  \n",
      "• Tools: PL/SQL developer,  JIRA, Confluence, Visual studio, GDB, Mercurial, Spirent Test \n",
      "Centre (STC), Wireshark  \n",
      "• Leadership and Team Collaboration  \n",
      " \n",
      "Project History:  \n",
      " \n",
      "Project#1 : EHI – Advantasure   \n",
      " \n",
      "Organization  : HCL Technologies - Madurai  \n",
      "Position  : Senior Technical Lead  \n",
      "Domain  : Health care  \n",
      "Technologies  : C, Pro C , PL/SQL, Linux  \n",
      " \n",
      "Description : This project involves in providing the support for the insurance \n",
      "company - Advantasure in healthcare domain. The major lines of business are \n",
      "Enrolment, Billing and Claims. Claims adjudication team involves in handling all business \n",
      "logics for processing a claim from submission to payment.  \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Contribution :\n",
      "Document No 3\n",
      "• Currently, working as the lead developer in a healthcare project based on USA.  \n",
      "• Leading the offshore development activities.  \n",
      "• Handling the PL SQL development team and working with the team   \n",
      "• Expertise in solving problems on complex SQL related to Reporting . \n",
      "• Expertise in creating the indexes on tables and partitioning the table for SQL tuning \n",
      "purpose  \n",
      "• Expertise in writing very complex SQL queries which are helpful for reporting \n",
      "purpose  \n",
      "• Expertise in writing procedures, functions, views and materialized views as required  \n",
      "• Having good experience on Client Interaction and Presentation Skills.  \n",
      " \n",
      "Project# 2: Support of CFM on the ONT  \n",
      " \n",
      "Organization  : Nokia Networks – formerly Alcatel -Lucent  \n",
      "Position  : Technical Lead  \n",
      "Domain  : L2/L3 protocol dev elopment  \n",
      "Technologies  : PL/SQL, C, shell scripting and Linux  \n",
      " \n",
      "Description : This feature is to enhance ALU’s ONT GPON access networking solution \n",
      "with support for IEEE802.1ag CFM & ITU -T y.1731 protocols to perform Ethernet fault \n",
      "and performance management activities.  \n",
      " \n",
      "Project# 3: DSCP tagging for L3 packets   \n",
      " \n",
      "Organization  : Nokia Networks – formerly Alcatel -Lucent  \n",
      "Position  : Technical Lead  \n",
      "Domain  : L2/L3 protocol dev elopment  \n",
      "Technologies  : C, shell scripting and Linux  \n",
      " \n",
      "Description : This feature is to provide the configurable DSCP tagging on packets to \n",
      "differentiate best quality for all services.  \n",
      " \n",
      "Project# 4: Dual TR069 stack development on ONT   \n",
      " \n",
      "Description : Dedicated TR069 connection to WHW SaaS Server, in order to keep the \n",
      "solution inde pendent of carriers existing CDP . Collecting the WiF i Care parameter from \n",
      "the Gateway via TR069, as and when required.  Configuring UPnP, WAN, LAN, DHCP, \n",
      "WLAN setting, All WiFi parameters, IP connectivity, Speed test, Firewall setting, might \n",
      "add port/application setting related to Wi -Fi care.\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for doc in docs:\n",
    "    cnt = cnt+1\n",
    "    print(\"Document No\",cnt)\n",
    "    print(doc.page_content.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You are given a resume as the below text.\n",
    "________\n",
    "{text}\n",
    "________\n",
    "Question: Please respond with the Key Skills and Experience summary of the person.\n",
    "Key Skills:\n",
    "Experience Summary:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(template=prompt_template, input_variables=[\"text\"])\n",
    "\n",
    "stuff_chain = load_summarize_chain(model, chain_type=\"stuff\", prompt=prompt)\n",
    "output_summary = stuff_chain.run(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Key Skills: \n",
      "- 12 years of experience in software development on Linux environment\n",
      "- Programming languages: PL/SQL, C, Pro C, Shell scripting\n",
      "- Database management: Oracle\n",
      "- Operating system: Linux\n",
      "- Version control: GIT, TFS, CVS\n",
      "- Tools: PL/SQL developer, JIRA, Confluence, Visual studio, GDB, Mercurial, Spirent Test Centre (STC), Wireshark\n",
      "- Leadership and team collaboration\n",
      "\n",
      "Experience Summary:\n",
      "- 12 years of experience in software development\n",
      "- Proven track record of successfully leading and collaborating with cross-functional teams\n",
      "- Expertise in all stages of Software Development Life Cycle\n",
      "- Experience with Oracle PL/SQL development and analysis, design, and implementation of business applications\n",
      "- Proficient in using table functions, indexes, table partitioning, collections, analytical functions, and materialized views\n",
      "- Skilled in creating tables, views, constraints, and indexes\n",
      "- Developed complex database objects such as packages, procedures, functions, and triggers using PL/SQL\n",
      "- Familiar with Oracle-supplied packages, dynamic SQL, records, and tables\n",
      "- Experience with data loading using SQL Loader\n",
      "- Knowledgeable in Oracle performance-related features such as query optimizer,\n"
     ]
    }
   ],
   "source": [
    "print(output_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refine Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point: {existing_answer}\n",
      "We have the opportunity to refine the existing summary (only if needed) with some more context below.\n",
      "------------\n",
      "{text}\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\n"
     ]
    }
   ],
   "source": [
    "refine_Chain = load_summarize_chain(model, chain_type=\"refine\")\n",
    "print(refine_Chain.refine_llm_chain.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nSunil Sharma is a highly experienced Senior Technical Lead with a Bachelor's degree in Engineering and 12 years of experience in software development. He has a strong track record of successfully leading cross-functional teams and delivering projects on time and within budget. Sunil is skilled in all stages of the software development life cycle and has expertise in Oracle PL/SQL development. He has worked in various organizations, including HCL Technologies, Nokia Networks, and Plintron Global Technology Solutions Pvt. Ltd. Sunil's skills include programming languages such as PL/SQL, C, Pro C, and shell scripting, as well as database management using Oracle and operating systems like Linux. He is also proficient in version control tools such as GIT, TFS, and CVS, and has experience with various software development tools. Sunil has experience in leading offshore development activities and handling a PL SQL development team. He is an expert in solving complex SQL problems and creating indexes and partitions for SQL tuning. Sunil also has experience in client interaction and presentation skills. His project history includes working on EHI-Advantasure for HCL Technologies, enhancing ALU's ONT GPON access networking solution for Nokia Networks, and developing features for DSCP tagging and dual TR069 stack on ONT. He\""
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_summary = refine_Chain.run(docs)\n",
    "output_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map-Reduce Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_reduce_chain = load_summarize_chain(model, chain_type=\"map_reduce\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write a concise summary of the following:\n",
      "\n",
      "\n",
      "\"{text}\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\n"
     ]
    }
   ],
   "source": [
    "print(map_reduce_chain.llm_chain.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MapReduceDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"        \n",
      "                                                 \n",
      "Name: Sunil Sharma                              Mobile: +91 9898989898  \n",
      " \n",
      "Designation: Senior Technical Lead                      Mail Id: sunil.sharma @gmail.com  \n",
      " \n",
      "Objective:   \n",
      "Experienced S enior Software Developer with 1 2 years of hands -on expertise in \n",
      "designing, developing, and delivering high -quality software solutions.  \n",
      "Proven track record of successfully leading and collaborating with cross -functional \n",
      "teams to deliver projects on time and within budget. Seeking to leverage my technical \n",
      "skills and leadership experience to contribute to innovative software projects.  \n",
      "Education:  \n",
      "Bachelor in Engineering in Electronics and Communication  \n",
      "K.L.N.  College of Information Technology, Madurai - 2007  \n",
      "Professional Summary:  \n",
      "• 12 years  of experience in Software Development in C on  Linux Environment . \n",
      "• Over 5 years of programming  experience as an Oracle PL/SQL  developer in \n",
      "Analysis, Design and Implementation of business application using Oracle DBMS . \n",
      "• Expertise in all stages of Software Development Life Cycle. \n",
      "• Effectively made use of Table functions, indexes, Table partitioning , Collections , \n",
      "Analytical functions  and materialized views . \n",
      "• Created tables, views, constraints  and indexes  (B Tree and function based).  \n",
      "• Developed complex DB objects like packages , procedures , functions  and triggers  \n",
      "using PL/SQL  \n",
      "• Experience in Oracle -supplied  packages, Dynamic SQL , records  and tables . \n",
      "• Loaded data into database tables using SQL Loader . \n",
      "• Good knowledge of Oracle performance -related features like query optimizer , \n",
      "execute plans  and indexes . \n",
      " \n",
      "Experience :  \n",
      "\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"     \n",
      "• Working as a Senior Technical Lead  in HCL-EHI project  since  August -2019 to till \n",
      "date  \n",
      " \n",
      "• Worked  as a Technical Lead  in NOKIA NETWORKS  in Research and Design \n",
      "Division of Protocol development and Digital Home  BU since August -2013  to \n",
      "September -2018  \n",
      " \n",
      "• Worked as a Senior Engineer  in Plintron  Global Technology Solutions Pvt. Ltd.  \n",
      " in Research and Design Division from June -2011 to August -2013  \n",
      " \n",
      "Skills:  \n",
      "• Programming  Languages:  PL/SQL, C, Pro C, Shell scripting  \n",
      "• Database Management: Oracle  \n",
      "• Operating System: Linux  \n",
      "• Version Control: GIT, TFS, CVS  \n",
      "• Tools: PL/SQL developer,  JIRA, Confluence, Visual studio, GDB, Mercurial, Spirent Test \n",
      "Centre (STC), Wireshark  \n",
      "• Leadership and Team Collaboration  \n",
      " \n",
      "Project History:  \n",
      " \n",
      "Project#1 : EHI – Advantasure   \n",
      " \n",
      "Organization  : HCL Technologies - Madurai  \n",
      "Position  : Senior Technical Lead  \n",
      "Domain  : Health care  \n",
      "Technologies  : C, Pro C , PL/SQL, Linux  \n",
      " \n",
      "Description : This project involves in providing the support for the insurance \n",
      "company - Advantasure in healthcare domain. The major lines of business are \n",
      "Enrolment, Billing and Claims. Claims adjudication team involves in handling all business \n",
      "logics for processing a claim from submission to payment.  \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Contribution : \"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"• Currently, working as the lead developer in a healthcare project based on USA.  \n",
      "• Leading the offshore development activities.  \n",
      "• Handling the PL SQL development team and working with the team   \n",
      "• Expertise in solving problems on complex SQL related to Reporting . \n",
      "• Expertise in creating the indexes on tables and partitioning the table for SQL tuning \n",
      "purpose  \n",
      "• Expertise in writing very complex SQL queries which are helpful for reporting \n",
      "purpose  \n",
      "• Expertise in writing procedures, functions, views and materialized views as required  \n",
      "• Having good experience on Client Interaction and Presentation Skills.  \n",
      " \n",
      "Project# 2: Support of CFM on the ONT  \n",
      " \n",
      "Organization  : Nokia Networks – formerly Alcatel -Lucent  \n",
      "Position  : Technical Lead  \n",
      "Domain  : L2/L3 protocol dev elopment  \n",
      "Technologies  : PL/SQL, C, shell scripting and Linux  \n",
      " \n",
      "Description : This feature is to enhance ALU’s ONT GPON access networking solution \n",
      "with support for IEEE802.1ag CFM & ITU -T y.1731 protocols to perform Ethernet fault \n",
      "and performance management activities.  \n",
      " \n",
      "Project# 3: DSCP tagging for L3 packets   \n",
      " \n",
      "Organization  : Nokia Networks – formerly Alcatel -Lucent  \n",
      "Position  : Technical Lead  \n",
      "Domain  : L2/L3 protocol dev elopment  \n",
      "Technologies  : C, shell scripting and Linux  \n",
      " \n",
      "Description : This feature is to provide the configurable DSCP tagging on packets to \n",
      "differentiate best quality for all services.  \n",
      " \n",
      "Project# 4: Dual TR069 stack development on ONT   \n",
      " \n",
      "Description : Dedicated TR069 connection to WHW SaaS Server, in order to keep the \n",
      "solution inde pendent of carriers existing CDP . Collecting the WiF i Care parameter from \n",
      "the Gateway via TR069, as and when required.  Configuring UPnP, WAN, LAN, DHCP, \n",
      "WLAN setting, All WiFi parameters, IP connectivity, Speed test, Firewall setting, might \n",
      "add port/application setting related to Wi -Fi care.  \"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\" Sunil Sharma is a highly experienced Senior Technical Lead with a Bachelor's degree in Engineering and 12 years of experience in software development. He has a proven track record of successfully leading cross-functional teams and delivering projects on time and within budget. He is skilled in Oracle PL/SQL development and has expertise in all stages of the Software Development Life Cycle. Sunil is seeking to leverage his technical skills and leadership experience to contribute to innovative software projects.\n",
      "\n",
      "\n",
      "\n",
      "The person has worked as a Senior Technical Lead in HCL-EHI project since August 2019. They also have experience as a Technical Lead in NOKIA NETWORKS and Senior Engineer in Plintron Global Technology Solutions Pvt. Ltd. They have skills in programming languages, database management, operating systems, version control, and various tools. They have experience in the healthcare domain and have worked on a project for an insurance company, handling business logic for claims processing. \n",
      "\n",
      " The individual is a lead developer for a healthcare project in the USA, overseeing offshore development and managing a PL SQL team. They have expertise in solving complex SQL problems and creating indexes and partitions for reporting purposes. They also have experience with client interaction and presentation skills. Additionally, they have worked on projects involving L2/L3 protocol development and technologies such as PL/SQL, C, shell scripting, and Linux. These projects include enhancing a networking solution with support for certain protocols, providing DSCP tagging for quality differentiation, and developing a dual TR069 stack for independent solution use.\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " Sunil Sharma is a highly experienced Senior Technical Lead with a Bachelor's degree in Engineering and 12 years of experience in software development. He has a proven track record of successfully leading cross-functional teams and delivering projects on time and within budget. He is skilled in Oracle PL/SQL development and has expertise in all stages of the Software Development Life Cycle. He has experience in healthcare and networking projects, and is seeking to contribute to innovative software projects.\n"
     ]
    }
   ],
   "source": [
    "output_summary = map_reduce_chain.run(docs)\n",
    "print(output_summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
